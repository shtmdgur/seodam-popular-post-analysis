{"cells":[{"cell_type":"markdown","metadata":{"id":"Oo3cLYHJ2Edp"},"source":["# Phase 1.5: í† í”½ ê²°ê³¼ ì‹¬ì¸µ ë¶„ì„\n","\n","Phase 1ì—ì„œ í•™ìŠµí•œ BERTopic ê²°ê³¼ë¬¼ì„ í™œìš©í•´ ê²Œì‹œíŒë³„ í† í”½ ê·œëª¨, í™œì„± ì‹œê°„ëŒ€, ëŒ€í‘œ ê¸€, ìŠ¤íƒ€ì¼ íŒíŠ¸ ë“±ì„ ì‹œê°í™”/ìš”ì•½í•©ë‹ˆë‹¤.\n","\n","## ëª©í‘œ\n","- ê° ê²Œì‹œíŒë³„ í† í”½ ë¶„í¬(ë§‰ëŒ€ ê·¸ë˜í”„) ë° í™œì„± ì‹œê°„ëŒ€ íˆíŠ¸ë§µ ìƒì„±\n","- BERTopic ì‹œê°í™”(ë„¤íŠ¸ì›Œí¬/ê³„ì¸µ/ë°” ì°¨íŠ¸) HTMLë¡œ ì €ì¥\n","- í† í”½ë³„ í‚¤ì›Œë“œ, ëŒ€í‘œ ê¸€, ìŠ¤íƒ€ì¼ í†µê³„ê°€ í¬í•¨ëœ ìš”ì•½ í…Œì´ë¸” ìƒì„±\n","- ì¶”í›„ Phase 2/3ì—ì„œ ì°¸ê³ í•  ìˆ˜ ìˆë„ë¡ CSV/Markdownë¡œ ë‚´ë³´ë‚´ê¸°\n"]},{"cell_type":"markdown","metadata":{"id":"vtLNDW0l2Eds"},"source":["---\n","## 0. íŒ¨í‚¤ì§€ ì„¤ì¹˜ (í•„ìš” ì‹œ)\n","\n","- ì´ ë…¸íŠ¸ë¶ì€ ì‹œê°í™”/ë¶„ì„ìš© íŒ¨í‚¤ì§€ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n","- ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ë©´ ê±´ë„ˆë›°ì…”ë„ ë©ë‹ˆë‹¤. Colab ëŸ°íƒ€ì„ì„ ìƒˆë¡œ ì—´ì—ˆë‹¤ë©´ í•œ ë²ˆë§Œ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"51PsexHF2Edt"},"outputs":[],"source":["%pip install -q pandas plotly seaborn matplotlib bertopic\n","\n","print(\"âœ… ë¶„ì„/ì‹œê°í™” íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\")\n","\n"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","# Google Drive ë§ˆìš´íŠ¸ (ì´ë¯¸ ë§ˆìš´íŠ¸ë˜ì–´ ìˆë‹¤ë©´ ê±´ë„ˆë›°ì–´ë„ ë©ë‹ˆë‹¤)\n","drive.mount('/content/drive', force_remount=True)\n","\n","print(\"âœ… Google Drive ë§ˆìš´íŠ¸ ì™„ë£Œ\")\n"],"metadata":{"id":"TY8cH5GN2Hbi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E3IxDHV22Edu"},"source":["---\n","## 0. ì „ì œ ì¡°ê±´ ë° ì…ë ¥ ë°ì´í„°\n","- `phase1_topic_modeling.ipynb`ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ `outputs/<ê²Œì‹œíŒ>_topics.parquet` ë° ê´€ë ¨ íŒŒì¼ì´ ìƒì„±ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n","- ì´ ë…¸íŠ¸ë¶ì€ í•´ë‹¹ ì¶œë ¥ë¬¼ì„ ì½ì–´ì„œ ì‹œê°í™”/ìš”ì•½ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ywLFWV9j2Edu"},"outputs":[],"source":["from pathlib import Path\n","from typing import Optional\n","import pandas as pd\n","import json\n","import plotly.express as px\n","import plotly.io as pio\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from bertopic import BERTopic\n","\n","pio.renderers.default = \"notebook_connected\"\n","sns.set_theme(style=\"whitegrid\")\n","\n","PROJECT_ROOT = Path(\"/content/drive/MyDrive/board_crawling\")\n","OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n","if not OUTPUT_DIR.exists():\n","    raise FileNotFoundError(\"outputs í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. Phase 1ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n","\n","print(f\"ğŸ“ OUTPUT_DIR: {OUTPUT_DIR}\")\n"]},{"cell_type":"markdown","metadata":{"id":"y7QZbpdG2Edu"},"source":["---\n","## 1. ì‚°ì¶œë¬¼ ë¡œë”© ìœ í‹¸ë¦¬í‹°\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NunON4I42Edv"},"outputs":[],"source":["def load_topic_artifacts(board_name: str):\n","    topics_path = OUTPUT_DIR / f\"{board_name}_topics.parquet\"\n","    info_path = OUTPUT_DIR / f\"{board_name}_topic_info.csv\"\n","    prompt_path = OUTPUT_DIR / f\"{board_name}_topics_for_prompt.json\"\n","    model_dir = OUTPUT_DIR / f\"bertopic_{board_name}\"\n","\n","    if not topics_path.exists():\n","        print(f\"âš ï¸ {board_name}: {topics_path} ì—†ìŒ â†’ ê±´ë„ˆëœ€\")\n","        return None\n","\n","    df_topics = pd.read_parquet(topics_path)\n","    topic_info = pd.read_csv(info_path) if info_path.exists() else None\n","    prompt_meta = None\n","    if prompt_path.exists():\n","        with open(prompt_path, \"r\", encoding=\"utf-8\") as f:\n","            prompt_meta = json.load(f)\n","\n","    return {\n","        \"df\": df_topics,\n","        \"topic_info\": topic_info,\n","        \"prompt_meta\": prompt_meta,\n","        \"model_dir\": model_dir if model_dir.exists() else None,\n","    }\n","\n","BOARD_ANALYSIS_TARGETS = [\n","    {\"board_name\": \"ìµê²Œ2\", \"label\": \"ìµê²Œ2\"},\n","    {\"board_name\": \"ììœ ê²Œì‹œíŒ\", \"label\": \"ììœ ê²Œì‹œíŒ\"},\n","    {\"board_name\": \"ì—°ì• ìƒë‹´ì†Œ\", \"label\": \"ì—°ì• ìƒë‹´ì†Œ\"},\n","    {\"board_name\": \"ìµê²Œ1\", \"label\": \"ìµê²Œ1\"},\n","    {\"board_name\": \"ì¸ê¸°ê¸€\", \"label\": \"ì¸ê¸°ê¸€\"},\n","]\n","\n","print(\"ë¶„ì„ ëŒ€ìƒ:\", [b[\"label\"] for b in BOARD_ANALYSIS_TARGETS])\n"]},{"cell_type":"markdown","metadata":{"id":"2uq5bZ9R2Edv"},"source":["---\n","## 2. ì‹œê°í™” í•¨ìˆ˜ (í† í”½ ë¶„í¬ / ì‹œê°„ëŒ€ íˆíŠ¸ë§µ / BERTopic HTML)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-6Svyhaw2Edw"},"outputs":[],"source":["def export_plotly(fig, html_path: Path, png_scale: int = 2):\n","    html_path.parent.mkdir(parents=True, exist_ok=True)\n","    fig.write_html(str(html_path))\n","    try:\n","        fig.write_image(str(html_path.with_suffix(\".png\")), scale=png_scale)\n","    except Exception as exc:\n","        print(f\"âš ï¸ PNG export ê±´ë„ˆëœ€({html_path.stem}): {exc}\")\n","    return html_path\n","\n","\n","def plot_topic_size_chart(df_topics: pd.DataFrame, board_name: str, pretty_name: str, top_n: int = 15):\n","    valid = df_topics[df_topics[\"topic\"] != -1].copy()\n","    if valid.empty:\n","        print(f\"âš ï¸ {pretty_name}: í• ë‹¹ëœ í† í”½ì´ ì—†ìŠµë‹ˆë‹¤.\")\n","        return None\n","\n","    stats = (\n","        valid.groupby(\"topic\")\n","        .agg(doc_count=(\"id\", \"count\"), avg_prob=(\"topic_prob\", \"mean\"))\n","        .reset_index()\n","        .sort_values(\"doc_count\", ascending=False)\n","        .head(top_n)\n","    )\n","    stats[\"avg_prob\"] = stats[\"avg_prob\"].round(4)\n","\n","    fig = px.bar(\n","        stats,\n","        x=\"doc_count\",\n","        y=stats[\"topic\"].astype(str),\n","        text=\"doc_count\",\n","        orientation=\"h\",\n","        title=f\"[{pretty_name}] Top {top_n} í† í”½ í¬ê¸°\",\n","        color=\"avg_prob\",\n","        color_continuous_scale=\"Blues\",\n","        labels={\"doc_count\": \"ë¬¸ì„œ ìˆ˜\", \"avg_prob\": \"í‰ê·  í™•ë¥ \"},\n","    )\n","    fig.update_layout(yaxis_title=\"Topic ID\", xaxis_title=\"ë¬¸ì„œ ìˆ˜\")\n","    export_path = OUTPUT_DIR / f\"{board_name}_topic_bar.html\"\n","    export_plotly(fig, export_path)\n","    return stats\n","\n","\n","def plot_time_heatmap(df_topics: pd.DataFrame, board_name: str, pretty_name: str,\n","                      kind: str = \"hour\", top_topics: int = 15):\n","    dt = pd.to_datetime(df_topics[\"date\"], errors=\"coerce\")\n","    frame = df_topics.copy()\n","    frame[\"topic\"] = frame[\"topic\"].astype(\"Int64\")\n","    frame = frame[(frame[\"topic\"] != -1) & dt.notna()].copy()\n","    if frame.empty:\n","        return None\n","\n","    frame[\"dt\"] = dt.loc[frame.index]\n","    if kind == \"hour\":\n","        frame[\"bucket\"] = frame[\"dt\"].dt.hour\n","        buckets = list(range(24))\n","        title_suffix = \"ì‹œê°„ëŒ€\"\n","    else:\n","        frame[\"bucket\"] = frame[\"dt\"].dt.dayofweek\n","        buckets = list(range(7))\n","        title_suffix = \"ìš”ì¼\"\n","\n","    pivot = frame.pivot_table(index=\"topic\", columns=\"bucket\", values=\"id\", aggfunc=\"count\", fill_value=0)\n","    if pivot.empty:\n","        return None\n","\n","    top_idx = frame[\"topic\"].value_counts().head(top_topics).index\n","    pivot = pivot.loc[pivot.index.isin(top_idx)]\n","    pivot = pivot.reindex(columns=buckets, fill_value=0)\n","    pivot[\"total\"] = pivot.sum(axis=1)\n","    pivot = pivot.sort_values(\"total\", ascending=False).drop(columns=\"total\")\n","\n","    fig = px.imshow(\n","        pivot,\n","        aspect=\"auto\",\n","        color_continuous_scale=\"YlGnBu\",\n","        title=f\"[{pretty_name}] í† í”½ë³„ {title_suffix}ë³„ í™œì„±ë„\",\n","        labels={\"x\": \"ì‹œê°„ëŒ€\" if kind == \"hour\" else \"ìš”ì¼(0=ì›”)\", \"y\": \"Topic\", \"color\": \"ë¬¸ì„œ ìˆ˜\"},\n","    )\n","    suffix = \"hour\" if kind == \"hour\" else \"dow\"\n","    export_plotly(fig, OUTPUT_DIR / f\"{board_name}_{suffix}_heatmap.html\")\n","    return pivot\n","\n","\n","def save_markdown_table(df: pd.DataFrame, path: Path, max_rows: int = 200):\n","    subset = df.head(max_rows)\n","    if subset.empty:\n","        return None\n","    header = \"| \" + \" | \".join(subset.columns) + \" |\\n\"\n","    divider = \"| \" + \" | \".join([\"---\"] * len(subset.columns)) + \" |\\n\"\n","    rows = \"\\n\".join(\n","        \"| \" + \" | \".join(str(value) for value in row) + \" |\"\n","        for row in subset.to_numpy()\n","    )\n","    path.parent.mkdir(parents=True, exist_ok=True)\n","    with open(path, \"w\", encoding=\"utf-8\") as f:\n","        f.write(header + divider + rows)\n","    return path\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LbBcqW7X2Edw"},"outputs":[],"source":["def export_bertopic_visuals(model_dir: Optional[Path], board_name: str):\n","    if model_dir is None or not model_dir.exists():\n","        return\n","    try:\n","        model = BERTopic.load(str(model_dir))\n","    except Exception as exc:\n","        print(f\"âš ï¸ {board_name}: BERTopic ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ â†’ {exc}\")\n","        return\n","\n","    viz_dir = OUTPUT_DIR / f\"{board_name}_viz\"\n","    viz_dir.mkdir(parents=True, exist_ok=True)\n","\n","    try:\n","        model.visualize_topics().write_html(str(viz_dir / \"topics.html\"))\n","        model.visualize_hierarchy().write_html(str(viz_dir / \"hierarchy.html\"))\n","        model.visualize_barchart().write_html(str(viz_dir / \"barchart.html\"))\n","        print(f\"âœ… {board_name}: BERTopic ì‹œê°í™” ì €ì¥ â†’ {viz_dir}\")\n","    except Exception as exc:\n","        print(f\"âš ï¸ {board_name}: ì‹œê°í™” ìƒì„± ì‹¤íŒ¨ â†’ {exc}\")\n"]},{"cell_type":"markdown","metadata":{"id":"r4qo0xMI2Edx"},"source":["---\n","## 3. ê²Œì‹œíŒ ë£¨í”„ ì‹¤í–‰\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s3ZyUG5J2Edx"},"outputs":[],"source":["topic_bar_records = []\n","time_rows = []\n","summary_rows = []\n","\n","for cfg in BOARD_ANALYSIS_TARGETS:\n","    board = cfg[\"board_name\"]\n","    pretty = cfg[\"label\"]\n","    artifacts = load_topic_artifacts(board)\n","    if artifacts is None:\n","        continue\n","\n","    df_topics = artifacts[\"df\"]\n","    stats = plot_topic_size_chart(df_topics, board, pretty, top_n=15)\n","    if stats is None or stats.empty:\n","        continue\n","\n","    stats = stats.assign(board=pretty)\n","    topic_bar_records.append(stats)\n","\n","    best_hours, best_dows = time_dow_helper(df_topics)\n","    time_rows.extend([\n","        {\n","            \"board\": pretty,\n","            \"topic\": int(t),\n","            \"best_hours\": \", \".join(map(str, best_hours.get(t, []))),\n","            \"best_dows\": \", \".join(map(str, best_dows.get(t, []))),\n","        }\n","        for t in stats[\"topic\"].tolist()\n","    ])\n","\n","    plot_time_heatmap(df_topics, board, pretty, kind=\"hour\")\n","    plot_time_heatmap(df_topics, board, pretty, kind=\"dow\")\n","\n","    prompt_meta = artifacts.get(\"prompt_meta\") or []\n","    prompt_map = {}\n","    if isinstance(prompt_meta, list):\n","        for entry in prompt_meta:\n","            topic_id = entry.get(\"topic\")\n","            if topic_id is not None:\n","                prompt_map[int(topic_id)] = entry\n","    elif isinstance(prompt_meta, dict):\n","        for key, entry in prompt_meta.items():\n","            try:\n","                topic_id = int(key)\n","            except Exception:\n","                continue\n","            prompt_map[topic_id] = entry\n","\n","    reps_df = representatives(df_topics, k=3)\n","    reps_map = reps_df.set_index(\"topic\")[\"representatives\"].to_dict() if not reps_df.empty else {}\n","\n","    for _, row in stats.iterrows():\n","        topic_id = int(row[\"topic\"])\n","        prompt_entry = prompt_map.get(topic_id, {})\n","        keywords = prompt_entry.get(\"keywords\", [])\n","        style_hints = prompt_entry.get(\"style_hints\", [])\n","\n","        summary_rows.append({\n","            \"board\": pretty,\n","            \"topic\": topic_id,\n","            \"doc_count\": int(row[\"doc_count\"]),\n","            \"avg_topic_prob\": float(row[\"avg_prob\"]),\n","            \"keywords\": \", \".join(keywords),\n","            \"best_hours\": \", \".join(map(str, best_hours.get(topic_id, []))),\n","            \"best_dows\": \", \".join(map(str, best_dows.get(topic_id, []))),\n","            \"representative_titles\": \" | \".join(rep.get(\"title\", \"\") for rep in reps_map.get(topic_id, [])) if reps_map else \"\",\n","            \"style_hints\": \" | \".join(style_hints) if style_hints else \"\",\n","        })\n","\n","    export_bertopic_visuals(artifacts.get(\"model_dir\"), board)\n"]},{"cell_type":"markdown","metadata":{"id":"nsUmlbJM2Edy"},"source":["if topic_bar_records:\n","    topic_bar_df = pd.concat(topic_bar_records, ignore_index=True)\n","    topic_bar_csv = OUTPUT_DIR / \"topic_bar_stats.csv\"\n","    topic_bar_df.to_csv(topic_bar_csv, index=False)\n","    print(f\"ğŸ“Š í† í”½ ë¶„í¬ ìš”ì•½ ì €ì¥: {topic_bar_csv}\")\n","\n","if time_rows:\n","    time_df = pd.DataFrame(time_rows).drop_duplicates()\n","    time_csv = OUTPUT_DIR / \"topic_time_summary.csv\"\n","    time_df.to_csv(time_csv, index=False)\n","    print(f\"â° ì‹œê°„ëŒ€/ìš”ì¼ ìš”ì•½ ì €ì¥: {time_csv}\")\n","\n","if summary_rows:\n","    summary_df = pd.DataFrame(summary_rows)\n","    summary_csv = OUTPUT_DIR / \"topic_summary.csv\"\n","    summary_md = OUTPUT_DIR / \"topic_summary.md\"\n","    summary_df.to_csv(summary_csv, index=False)\n","    save_markdown_table(summary_df, summary_md)\n","    display(summary_df.head(20))\n","    print(f\"ğŸ“ í† í”½ Summary ì €ì¥: {summary_csv}, {summary_md}\")\n","else:\n","    print(\"âš ï¸ ìš”ì•½ ë°ì´í„°ê°€ ì—†ì–´ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n"]},{"cell_type":"markdown","metadata":{"id":"wEBciLBZ2Edy"},"source":["---\n","## 4. ì™„ë£Œ ì•ˆë‚´\n","- ìœ„ ì‚°ì¶œë¬¼ì€ ëª¨ë‘ `outputs/` ë””ë ‰í„°ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤.\n","- Phase 2ì—ì„œëŠ” `topic_summary.csv`ì™€ `ì¸ê¸°ê¸€_topics_for_prompt.json` ë“±ì„ í™œìš©í•´ Instruction Tuning ë°ì´í„°ì…‹ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n","- ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•˜ë©´ ë³¸ ë…¸íŠ¸ë¶ì„ ìˆ˜ì •í•´ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","âš¡ **Tip**: ì‹œê°í™” HTML/PNG íŒŒì¼ì€ Google Driveì—ì„œ ì§ì ‘ ì—´ì–´ í™•ì¸í•˜ì„¸ìš”.\n"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}