{"cells":[{"cell_type":"markdown","metadata":{"id":"E_Zw0_MA2Qxk"},"source":["# Phase 4: Fine-tuned 모델로 인기글 생성\n","\n","Phase 3에서 저장한 파인튜닝 모델을 로드하여 각 게시판별 키워드로 새로운 인기글을 생성합니다.\n"]},{"cell_type":"markdown","metadata":{"id":"h-sqkUyg2Qxn"},"source":["## ⚙️ 사전 조건\n","- `phase1_topic_modeling.ipynb` 실행으로 `*_topics_for_prompt.json` 파일 존재\n","- `phase3_finetune.ipynb` 실행으로 `models/llama3_popular_post_lora` (및 merged_16bit) 존재\n","- GPU 런타임 할당\n"]},{"cell_type":"markdown","metadata":{"id":"HQopAdWX2Qxo"},"source":["---\n","## 0. 패키지 설치 (필요 시)\n","- Unsloth/transformers 가 설치되지 않았다면 Phase 3의 설치 셀을 재사용하세요.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JdJtI6V32Qxo"},"outputs":[],"source":["# Phase 4에서 사용하는 최소 패키지 설치\n","# - Unsloth: 파인튜닝된 Llama-3 모델 로드 및 추론용\n","# - pandas: 생성 결과를 DataFrame/CSV로 저장하기 위해 사용\n","\n","%pip install -q \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\" pandas\n","\n","print(\"✅ Phase 4 추론용 패키지 설치 완료\")\n"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","# Google Drive 마운트 (이미 마운트되어 있다면 건너뛰어도 됩니다)\n","drive.mount('/content/drive', force_remount=True)\n","\n","print(\"✅ Google Drive 마운트 완료\")\n"],"metadata":{"id":"EhcV4_Rd2ReA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"25lDVK_i2Qxp"},"source":["---\n","## 1. 경로 설정 및 키워드 로드\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g2D3E_5x2Qxq"},"outputs":[],"source":["from pathlib import Path\n","import json\n","import pandas as pd\n","from IPython.display import display\n","\n","PROJECT_ROOT = Path(\"/content/drive/MyDrive/board_crawling\")\n","OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n","MODEL_DIR = PROJECT_ROOT / \"models\"\n","OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n","MODEL_DIR.mkdir(parents=True, exist_ok=True)\n","\n","PROMPT_FILES = {\n","    \"익게2\": OUTPUT_DIR / \"익게2_topics_for_prompt.json\",\n","    \"자유게시판\": OUTPUT_DIR / \"자유게시판_topics_for_prompt.json\",\n","    \"연애상담소\": OUTPUT_DIR / \"연애상담소_topics_for_prompt.json\",\n","    \"익게1\": OUTPUT_DIR / \"익게1_topics_for_prompt.json\",\n","}\n","\n","trend_keywords = {}\n","for board, path in PROMPT_FILES.items():\n","    if not path.exists():\n","        print(f\"⚠️ {board}: {path} 없음 → 건너뜀\")\n","        continue\n","    with open(path, \"r\", encoding=\"utf-8\") as f:\n","        topics_data = json.load(f)\n","    top_topics = sorted(topics_data, key=lambda x: len(x.get(\"representatives\", [])), reverse=True)[:5]\n","    keywords = []\n","    for topic in top_topics:\n","        kw = topic.get(\"keywords\", [])\n","        if isinstance(kw, list):\n","            keywords.extend(kw[:8])\n","    trend_keywords[board] = list(dict.fromkeys(keywords))[:8]\n","    print(f\"✅ {board}: {len(trend_keywords[board])}개 키워드\")\n","\n","if not trend_keywords:\n","    raise RuntimeError(\"키워드가 없습니다. Phase 1 노트북을 먼저 실행하세요.\")\n"]},{"cell_type":"markdown","metadata":{"id":"Ey09SLP92Qxq"},"source":["---\n","## 2. 파인튜닝 모델 로드\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NV-jdWo82Qxq"},"outputs":[],"source":["from unsloth import FastLanguageModel\n","\n","FINETUNED_DIR = MODEL_DIR / \"llama3_popular_post_lora\"\n","if not FINETUNED_DIR.exists():\n","    raise FileNotFoundError(f\"{FINETUNED_DIR}가 없습니다. Phase 3을 먼저 실행하세요.\")\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name=str(FINETUNED_DIR),\n","    max_seq_length=2048,\n","    dtype=None,\n","    load_in_4bit=True,\n",")\n","\n","FastLanguageModel.for_inference(model)\n","print(\"✅ 파인튜닝 모델 로드 완료\")\n"]},{"cell_type":"markdown","metadata":{"id":"XPlfyX1V2Qxr"},"source":["---\n","## 3. 생성 함수 정의\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UfsG7P9a2Qxr"},"outputs":[],"source":["import torch\n","\n","def generate_post(board_name: str, keywords: list, temperature=0.7, max_new_tokens=800):\n","    instruction = f\"주어진 키워드를 사용하여 {board_name}의 인기글 스타일로 글을 작성해줘.\"\n","    input_text = f\"키워드: {', '.join(keywords)}\"\n","    prompt = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{instruction}\n","\n","### Input:\n","{input_text}\n","\n","### Response:\n","\"\"\"\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model.generate(\n","        **inputs,\n","        max_new_tokens=max_new_tokens,\n","        temperature=temperature,\n","        do_sample=True,\n","        pad_token_id=tokenizer.eos_token_id,\n","    )\n","    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    if \"### Response:\" in generated_text:\n","        response = generated_text.split(\"### Response:\")[-1].strip()\n","    else:\n","        response = generated_text.strip()\n","    return response\n","\n","\n","def split_title_content(text: str):\n","    lines = text.strip().split(\"\\n\")\n","    if len(lines) > 1:\n","        title = lines[0].strip()\n","        content = \"\\n\".join(lines[1:]).strip()\n","    else:\n","        title = text[:50].strip() + \"...\" if len(text) > 50 else text.strip()\n","        content = text.strip()\n","    return title, content\n"]},{"cell_type":"markdown","metadata":{"id":"dirgrh6F2Qxr"},"source":["---\n","## 4. 게시판별 생성 실행\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qy39ykoR2Qxs"},"outputs":[],"source":["from datetime import datetime\n","\n","generated_posts = []\n","for board, keywords in trend_keywords.items():\n","    if not keywords:\n","        continue\n","    print(f\"\\n생성 중: {board} ({', '.join(keywords[:5])}...)\")\n","    try:\n","        generated_text = generate_post(board, keywords, temperature=0.7, max_new_tokens=800)\n","        title, content = split_title_content(generated_text)\n","        generated_posts.append({\n","            \"board_name\": board,\n","            \"keywords\": \", \".join(keywords),\n","            \"generated_title\": title,\n","            \"generated_content\": content,\n","            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n","        })\n","        print(f\"✅ {board} 생성 완료\")\n","    except Exception as exc:\n","        print(f\"⚠️ {board} 생성 실패: {exc}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dt2WWp0C2Qxs"},"outputs":[],"source":["if generated_posts:\n","    result_df = pd.DataFrame(generated_posts)\n","    output_csv = OUTPUT_DIR / \"generated_posts.csv\"\n","    result_df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n","    print(f\"\\n✅ 생성 결과 저장 완료: {output_csv}\")\n","    display(result_df[[\"board_name\", \"generated_title\"]].head())\n","else:\n","    print(\"⚠️ 생성된 게시글이 없습니다.\")\n"]},{"cell_type":"markdown","metadata":{"id":"h_COZI8Q2Qxs"},"source":["---\n","## 5. 추가 팁\n","- 생성 결과를 수작업으로 검토하여 품질 확인 후 배포하세요.\n","- 다른 샘플을 얻고 싶다면 `temperature`, `max_new_tokens`, 키워드 조합 등을 조정할 수 있습니다.\n","- 모델을 공유하려면 Phase 3에서 저장한 merged 모델을 업로드하거나 Hugging Face Hub에 push 하면 됩니다.\n"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}