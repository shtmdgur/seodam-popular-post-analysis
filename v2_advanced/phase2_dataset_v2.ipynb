{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTf8g1s-87C0"
      },
      "source": [
        "# Phase 2v2: RPM ê¸°ë°˜ ê³ ë„í™” Instruction ë°ì´í„°ì…‹ êµ¬ì¶•\n",
        "\n",
        "## ğŸ“Œ ëª©ì \n",
        "RPM(Reasoning-Level Personalization, arXiv:2505.21082) ë…¼ë¬¸ì˜ ë°©ë²•ë¡ ì„ ì ìš©í•˜ì—¬,\n",
        "ì¸ê¸°ê¸€ì˜ **ì¸ê¸° ìš”ì¸ì„ í”¼ì²˜ë¡œ ì¶”ì¶œ â†’ íŒ©í„°ë¡œ í´ëŸ¬ìŠ¤í„°ë§ â†’ ì¶”ë¡ ê²½ë¡œ(CoT) ìƒì„±**í•˜ê³ ,\n",
        "SOS/EOS í† í°ì´ í¬í•¨ëœ ê³ í’ˆì§ˆ í•™ìŠµ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
        "\n",
        "### RPM íŒŒì´í”„ë¼ì¸\n",
        "```\n",
        "Step 1: Feature Extraction    â€” ê° ì¸ê¸°ê¸€ì—ì„œ ì¸ê¸° ê¸°ì—¬ í”¼ì²˜ë¥¼ Geminië¡œ ì¶”ì¶œ\n",
        "Step 2: Factor Construction   â€” í”¼ì²˜ë“¤ì„ LLM ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§(PAS)ìœ¼ë¡œ íŒ©í„° êµ¬ì„±\n",
        "Step 3: Reasoning Path        â€” íŒ©í„° ê¸°ë°˜ìœ¼ë¡œ ì¶”ë¡ ê²½ë¡œ ìƒì„± (= CoT)\n",
        "Step 4: Dataset Generation    â€” SOS/EOS + CoT í†µí•© JSONL ìƒì„±\n",
        "```\n",
        "\n",
        "## âš™ï¸ ì‚¬ì „ ì¡°ê±´\n",
        "- `phase0_preprocessing_v2.ipynb` ì‹¤í–‰ìœ¼ë¡œ `outputs/ì¸ê¸°ê¸€_clean_v2.parquet` ì¡´ì¬\n",
        "- Colab ì‹œí¬ë¦¿ì— `GEMINI_API_KEY` ë“±ë¡ (ì¢Œì¸¡ ğŸ”‘ ì•„ì´ì½˜)\n",
        "\n",
        "## ğŸ“‚ ì¶œë ¥ íŒŒì¼\n",
        "```\n",
        "outputs/\n",
        "â”œâ”€â”€ rpm_features.json            # Step 1: ì¶”ì¶œëœ í”¼ì²˜\n",
        "â”œâ”€â”€ rpm_factors.json             # Step 2: í´ëŸ¬ìŠ¤í„°ë§ëœ íŒ©í„°\n",
        "â”œâ”€â”€ rpm_reasoning_paths.json     # Step 3: ì¶”ë¡ ê²½ë¡œ\n",
        "â””â”€â”€ training_dataset_v2.jsonl    # Step 4: ìµœì¢… í•™ìŠµ ë°ì´í„°ì…‹\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv7J8kbc87C2"
      },
      "source": [
        "---\n",
        "## 0. íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARsvBlBY87C2"
      },
      "outputs": [],
      "source": [
        "%pip install -q pandas numpy google-generativeai tqdm\n",
        "\n",
        "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsMMYRNg87C3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive, userdata\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "print(\"âœ… Google Drive ë§ˆìš´íŠ¸ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OkhgPhm87C3"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import display\n",
        "\n",
        "# â”€â”€ Gemini API ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "gemini_model = genai.GenerativeModel('gemini-flash-latest')\n",
        "\n",
        "print(\"âœ… Gemini API ì—°ê²° ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "    if \"generateContent\" in [ms for ms in m.supported_generation_methods]:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "id": "eJfXib-jRTGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PniDIOy87C4"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/board_crawling\")\n",
        "OUTPUT_DIR   = PROJECT_ROOT / \"outputs\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# â”€â”€ ë°ì´í„° ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "HOT_PARQUET = OUTPUT_DIR / \"ì¸ê¸°ê¸€_clean_v2.parquet\"\n",
        "if not HOT_PARQUET.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"{HOT_PARQUET}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. phase0_preprocessing_v2.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\"\n",
        "    )\n",
        "\n",
        "hot_df = pd.read_parquet(HOT_PARQUET)\n",
        "print(f\"âœ… ì¸ê¸°ê¸€ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(hot_df):,}í–‰\")\n",
        "\n",
        "# engagement score ê¸°ë°˜ ìƒìœ„ 2,000ê°œ í•„í„°ë§\n",
        "# ì¶”ì²œìˆ˜ + ëŒ“ê¸€ìˆ˜Ã—0.5 ê°€ì¤‘í•©ìœ¼ë¡œ \"ì¸ê¸°ë„\"ê°€ ë†’ì€ ê¸€ ìš°ì„  ì„ íƒ\n",
        "TOP_K = 2000\n",
        "# Fix: Ensure a Series of 0s is used if the column doesn't exist\n",
        "recommend_values = hot_df.get(\"recommend\", pd.Series(0, index=hot_df.index))\n",
        "hot_df[\"recommend\"] = pd.to_numeric(recommend_values, errors=\"coerce\").fillna(0)\n",
        "\n",
        "comment_count_values = hot_df.get(\"comment_count\", pd.Series(0, index=hot_df.index))\n",
        "hot_df[\"comment_count\"] = pd.to_numeric(comment_count_values, errors=\"coerce\").fillna(0)\n",
        "\n",
        "hot_df[\"engagement_score\"] = hot_df[\"recommend\"] + hot_df[\"comment_count\"] * 0.5\n",
        "# ê²Œì‹œíŒë³„ ë¹„ë¡€ ìƒ˜í”Œë§ (íŠ¹ì • ê²Œì‹œíŒ ì ë¦¼ ë°©ì§€)\n",
        "hot_df = (\n",
        "    hot_df\n",
        "    .sort_values(\"engagement_score\", ascending=False)\n",
        "    .groupby(\"board\", group_keys=False)\n",
        "    .apply(lambda g: g.head(max(1, int(len(g) / len(hot_df) * TOP_K))))\n",
        ")\n",
        "print(f\"âœ… ìƒìœ„ {len(hot_df):,}ê±´ í•„í„°ë§ ì™„ë£Œ (engagement_score ê¸°ì¤€)\")\n",
        "# â”€â”€ ğŸ”¼ ì—¬ê¸°ê¹Œì§€ ì¶”ê°€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(f\"ğŸ“Š ê²Œì‹œíŒ ë¶„í¬:\")\n",
        "print(hot_df[\"board\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ujwjbne87C4"
      },
      "source": [
        "---\n",
        "## 1. Gemini API í—¬í¼ í•¨ìˆ˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtATR7Ed87C4"
      },
      "outputs": [],
      "source": [
        "def call_gemini(prompt: str, max_retries: int = 3, temperature: float = 0.0) -> str:\n",
        "    \"\"\"\n",
        "    Gemini API í˜¸ì¶œ (ì¬ì‹œë„ + Rate Limit ëŒ€ì‘).\n",
        "    \"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = gemini_model.generate_content(\n",
        "                prompt,\n",
        "                generation_config=genai.types.GenerationConfig(\n",
        "                    temperature=temperature,\n",
        "                    max_output_tokens=1024,\n",
        "                ),\n",
        "            )\n",
        "            return response.text.strip()\n",
        "        except Exception as e:\n",
        "            error_str = str(e).lower()\n",
        "            if \"rate\" in error_str or \"quota\" in error_str or \"429\" in error_str:\n",
        "                wait_time = 15 * (attempt + 1)\n",
        "                print(f\"  â³ Rate limit, {wait_time}ì´ˆ ëŒ€ê¸° (ì‹œë„ {attempt+1}/{max_retries})\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                print(f\"  âš ï¸ Gemini í˜¸ì¶œ ì‹¤íŒ¨: {e}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    time.sleep(5)\n",
        "                else:\n",
        "                    return \"\"\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "def parse_json_response(text: str) -> dict | list | None:\n",
        "    \"\"\"\n",
        "    Gemini ì‘ë‹µì—ì„œ JSONì„ ì¶”ì¶œ.\n",
        "    ```json ... ``` ë¸”ë¡ì´ ìˆìœ¼ë©´ ê·¸ ì•ˆì˜ ë‚´ìš©ì„, ì—†ìœ¼ë©´ ì „ì²´ë¥¼ íŒŒì‹± ì‹œë„.\n",
        "    \"\"\"\n",
        "    # markdown json ë¸”ë¡ ì¶”ì¶œ\n",
        "    match = re.search(r'```(?:json)?\\s*\\n?(.*?)\\n?```', text, re.DOTALL)\n",
        "    if match:\n",
        "        text = match.group(1).strip()\n",
        "\n",
        "    try:\n",
        "        return json.loads(text)\n",
        "    except json.JSONDecodeError:\n",
        "        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ ì‹œë„\n",
        "        for start_char, end_char in [('{', '}'), ('[', ']')]:\n",
        "            start = text.find(start_char)\n",
        "            end = text.rfind(end_char)\n",
        "            if start != -1 and end != -1 and end > start:\n",
        "                try:\n",
        "                    return json.loads(text[start:end+1])\n",
        "                except json.JSONDecodeError:\n",
        "                    continue\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"âœ… í—¬í¼ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfxqsCOW87C5"
      },
      "source": [
        "---\n",
        "## 2. RPM Step 1: Feature Extraction (í”¼ì²˜ ì¶”ì¶œ)\n",
        "\n",
        "ê° ì¸ê¸°ê¸€ì—ì„œ **\"ì¸ê¸°ì— ê¸°ì—¬í•˜ëŠ” ìš”ì†Œ(response-influential features)\"**ë¥¼ Geminië¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
        "\n",
        "RPM ë…¼ë¬¸ì˜ `G_qi = M(qi)` ì— í•´ë‹¹í•˜ë©°, ê° í”¼ì²˜ëŠ” `(name, context)` ìŒìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsAThOLB87C5"
      },
      "outputs": [],
      "source": [
        "FEATURE_EXTRACTION_PROMPT = \"\"\"\n",
        "ë‹¹ì‹ ì€ ëŒ€í•™ ì»¤ë®¤ë‹ˆí‹° 'ì„œë‹´'ì˜ ì¸ê¸°ê¸€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
        "\n",
        "ë‹¤ìŒ ì¸ê¸°ê¸€ì—ì„œ, ì´ ê¸€ì´ ì¸ê¸°ë¥¼ ì–»ëŠ” ë° ê¸°ì—¬í•œ í•µì‹¬ ìš”ì†Œ(feature)ë“¤ì„ ì¶”ì¶œí•˜ì„¸ìš”.\n",
        "ê° í”¼ì²˜ëŠ” ê¸€ì˜ ë‚´ìš©/êµ¬ì¡°/ìŠ¤íƒ€ì¼ì—ì„œ ë…ìì˜ ê´€ì‹¬ê³¼ ê³µê°ì„ ì´ëŒì–´ë‚´ëŠ” ìš”ì¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "[ê²Œì‹œíŒ] {board}\n",
        "[ì œëª©] {title}\n",
        "[ë‚´ìš©]\n",
        "{contents}\n",
        "\n",
        "3~5ê°œì˜ í”¼ì²˜ë¥¼ ì¶”ì¶œí•˜ì—¬ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:\n",
        "{{\n",
        "  \"features\": [\n",
        "    {{\"feature_name\": \"í”¼ì²˜ì˜ ì˜ë¯¸ì  ë¼ë²¨\", \"context\": \"ì´ í”¼ì²˜ê°€ ê¸€ì—ì„œ ì–´ë–»ê²Œ ë‚˜íƒ€ë‚˜ëŠ”ì§€ êµ¬ì²´ì  ì„¤ëª…\"}},\n",
        "    ...\n",
        "  ]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ… Feature Extraction í”„ë¡¬í”„íŠ¸ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uR4NUggW87C5"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ í”¼ì²˜ ì¶”ì¶œ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# ìºì‹œ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ ìƒˆë¡œ ì¶”ì¶œ\n",
        "FEATURES_CACHE = OUTPUT_DIR / \"rpm_features.json\"\n",
        "\n",
        "if FEATURES_CACHE.exists():\n",
        "    with open(FEATURES_CACHE, \"r\", encoding=\"utf-8\") as f:\n",
        "        all_features = json.load(f)\n",
        "    print(f\"âœ… ìºì‹œì—ì„œ í”¼ì²˜ ë¡œë“œ: {len(all_features)}ê±´\")\n",
        "else:\n",
        "    all_features = {}  # key: post_key(str), value: {\"features\": [...]}\n",
        "\n",
        "# ì•„ì§ ì¶”ì¶œ ì•ˆ ëœ ê²Œì‹œê¸€ë§Œ ì²˜ë¦¬\n",
        "remaining = hot_df[~hot_df[\"post_key\"].astype(str).isin(all_features.keys())]\n",
        "print(f\"ğŸ“ ì¶”ì¶œ ëŒ€ìƒ: {len(remaining):,}ê±´ (ì´ë¯¸ ì™„ë£Œ: {len(all_features):,}ê±´)\")\n",
        "\n",
        "# ì²˜ë¦¬ + ì£¼ê¸°ì  ì €ì¥\n",
        "SAVE_INTERVAL = 50\n",
        "for idx, (_, row) in enumerate(tqdm(remaining.iterrows(), total=len(remaining), desc=\"í”¼ì²˜ ì¶”ì¶œ\")):\n",
        "    post_key = str(row[\"post_key\"])\n",
        "    title = str(row.get(\"title\", \"\")).strip()\n",
        "    contents = str(row.get(\"contents\", \"\")).strip()[:1500]  # í† í° ì œí•œ\n",
        "    board = str(row.get(\"board\", \"\")).strip()\n",
        "\n",
        "    prompt = FEATURE_EXTRACTION_PROMPT.format(\n",
        "        board=board, title=title, contents=contents\n",
        "    )\n",
        "\n",
        "    response_text = call_gemini(prompt)\n",
        "    parsed = parse_json_response(response_text)\n",
        "\n",
        "    if parsed and \"features\" in parsed:\n",
        "        all_features[post_key] = parsed\n",
        "    else:\n",
        "        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í”¼ì²˜\n",
        "        all_features[post_key] = {\n",
        "            \"features\": [\n",
        "                {\"feature_name\": \"ë‚´ìš©_êµ¬ì„±\", \"context\": title}\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    # ì£¼ê¸°ì  ì €ì¥ (ì¤‘ë‹¨ ëŒ€ë¹„)\n",
        "    if (idx + 1) % SAVE_INTERVAL == 0:\n",
        "        with open(FEATURES_CACHE, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(all_features, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"  ğŸ’¾ ì¤‘ê°„ ì €ì¥ ({len(all_features)}ê±´)\")\n",
        "\n",
        "    # Rate limit ë°©ì§€\n",
        "    time.sleep(0.3)\n",
        "\n",
        "# ìµœì¢… ì €ì¥\n",
        "with open(FEATURES_CACHE, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(all_features, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\nâœ… í”¼ì²˜ ì¶”ì¶œ ì™„ë£Œ: {len(all_features)}ê±´ â†’ {FEATURES_CACHE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewIWNhI387C5"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ í”¼ì²˜ ì¶”ì¶œ ê²°ê³¼ ìƒ˜í”Œ í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "sample_keys = list(all_features.keys())[:3]\n",
        "for key in sample_keys:\n",
        "    row = hot_df[hot_df[\"post_key\"].astype(str) == key].iloc[0]\n",
        "    print(f\"\\nğŸ“ [{row['board']}] {row['title'][:50]}\")\n",
        "    for feat in all_features[key][\"features\"]:\n",
        "        print(f\"  â†’ {feat['feature_name']}: {feat['context'][:80]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4k1QoG987C5"
      },
      "source": [
        "---\n",
        "## 3. RPM Step 2: Factor Construction (íŒ©í„° êµ¬ì„±)\n",
        "\n",
        "ì¶”ì¶œëœ í”¼ì²˜ë“¤ì„ **LLM ê¸°ë°˜ ì‹œë§¨í‹± í´ëŸ¬ìŠ¤í„°ë§(PAS: Propose-Assign-Select)**ìœ¼ë¡œ\n",
        "ìƒìœ„ íŒ©í„°(Factor)ë¡œ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.\n",
        "\n",
        "RPM ë…¼ë¬¸ Section 3.2ì˜ Factor Generation í”„ë¡œì„¸ìŠ¤ì— í•´ë‹¹í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mnmvIOS87C6"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ ì „ì²´ í”¼ì²˜ í’€ êµ¬ì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "feature_pool = []  # [{\"feature_name\": ..., \"context\": ..., \"post_key\": ...}, ...]\n",
        "for post_key, data in all_features.items():\n",
        "    for feat in data.get(\"features\", []):\n",
        "        feature_pool.append({\n",
        "            \"feature_name\": feat.get(\"feature_name\", \"\"),\n",
        "            \"context\": feat.get(\"context\", \"\"),\n",
        "            \"post_key\": post_key,\n",
        "        })\n",
        "\n",
        "print(f\"ğŸ“Š ì „ì²´ í”¼ì²˜ í’€: {len(feature_pool):,}ê°œ\")\n",
        "\n",
        "# í”¼ì²˜ ì´ë¦„ ë¹ˆë„ í™•ì¸\n",
        "name_counts = Counter(f[\"feature_name\"] for f in feature_pool)\n",
        "print(\"\\nğŸ” ìƒìœ„ 20ê°œ í”¼ì²˜ ì´ë¦„:\")\n",
        "for name, count in name_counts.most_common(20):\n",
        "    print(f\"  {name}: {count}íšŒ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvWZ7LbP87C6"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ PAS Step 1: Propose (íŒ©í„° í›„ë³´ ì œì•ˆ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "FACTORS_CACHE = OUTPUT_DIR / \"rpm_factors.json\"\n",
        "\n",
        "if FACTORS_CACHE.exists():\n",
        "    with open(FACTORS_CACHE, \"r\", encoding=\"utf-8\") as f:\n",
        "        factors_data = json.load(f)\n",
        "    print(f\"âœ… ìºì‹œì—ì„œ íŒ©í„° ë¡œë“œ: {len(factors_data['factors'])}ê°œ íŒ©í„°\")\n",
        "else:\n",
        "    # ëœë¤ ìƒ˜í”Œ 30%ë¡œ íŒ©í„° í›„ë³´ ì œì•ˆ\n",
        "    np.random.seed(42)\n",
        "    sample_size = min(len(feature_pool), max(100, int(len(feature_pool) * 0.3)))\n",
        "    sampled_features = np.random.choice(\n",
        "        [f\"{f['feature_name']}: {f['context'][:60]}\" for f in feature_pool],\n",
        "        size=sample_size,\n",
        "        replace=False\n",
        "    ).tolist()\n",
        "\n",
        "    propose_prompt = f\"\"\"\n",
        "ë‹¹ì‹ ì€ ëŒ€í•™ ì»¤ë®¤ë‹ˆí‹° ì¸ê¸°ê¸€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
        "\n",
        "ë‹¤ìŒì€ ì„œë‹´ ì»¤ë®¤ë‹ˆí‹° ì¸ê¸°ê¸€ì—ì„œ ì¶”ì¶œëœ í”¼ì²˜(ì¸ê¸° ê¸°ì—¬ ìš”ì†Œ)ë“¤ì˜ ìƒ˜í”Œì…ë‹ˆë‹¤:\n",
        "\n",
        "{chr(10).join(f'- {feat}' for feat in sampled_features[:80])}\n",
        "\n",
        "ì´ í”¼ì²˜ë“¤ì„ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì„ ìˆ˜ ìˆëŠ” ìƒìœ„ íŒ©í„°(Factor)ë¥¼ 5~8ê°œ ì œì•ˆí•˜ì„¸ìš”.\n",
        "ê° íŒ©í„°ëŠ” ì¸ê¸°ê¸€ì˜ ì¸ê¸° ìš”ì¸ ìœ í˜•ì„ ëŒ€í‘œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:\n",
        "{{\n",
        "  \"factors\": [\n",
        "    {{\n",
        "      \"factor_name\": \"íŒ©í„° ì´ë¦„\",\n",
        "      \"description\": \"ì´ íŒ©í„°ê°€ ì˜ë¯¸í•˜ëŠ” ë°”ì— ëŒ€í•œ ì„¤ëª…\"\n",
        "    }},\n",
        "    ...\n",
        "  ]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "    propose_response = call_gemini(propose_prompt, temperature=0.5)\n",
        "    proposed_factors = parse_json_response(propose_response)\n",
        "\n",
        "    if proposed_factors and \"factors\" in proposed_factors:\n",
        "        print(f\"âœ… íŒ©í„° í›„ë³´ ì œì•ˆ ì™„ë£Œ: {len(proposed_factors['factors'])}ê°œ\")\n",
        "        for f in proposed_factors[\"factors\"]:\n",
        "            print(f\"  â†’ {f['factor_name']}: {f['description'][:60]}\")\n",
        "    else:\n",
        "        # ì œì•ˆ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ íŒ©í„°\n",
        "        proposed_factors = {\n",
        "            \"factors\": [\n",
        "                {\"factor_name\": \"ê°ì •ì _ê³µê°\", \"description\": \"ë…ìì˜ ê°ì •ì  ê³µê°ì„ ìœ ë°œí•˜ëŠ” ë‚´ìš©ì´ë‚˜ ì–´íˆ¬\"},\n",
        "                {\"factor_name\": \"ìœ ë¨¸_ë°˜ì „\", \"description\": \"ì›ƒìŒì„ ìœ ë°œí•˜ëŠ” ìœ ë¨¸ëŸ¬ìŠ¤í•œ ë‚´ìš©ì´ë‚˜ ë°˜ì „ ìš”ì†Œ\"},\n",
        "                {\"factor_name\": \"ì •ë³´_ì „ë‹¬\", \"description\": \"ìœ ìš©í•œ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” êµ¬ì¡°ë‚˜ ë‚´ìš©\"},\n",
        "                {\"factor_name\": \"ì°¸ì—¬_ìœ ë„\", \"description\": \"ì§ˆë¬¸/íˆ¬í‘œ ë“±ìœ¼ë¡œ ë…ìì˜ ì ê·¹ì  ì°¸ì—¬ë¥¼ ìœ ë„\"},\n",
        "                {\"factor_name\": \"ì¼ìƒ_ê³µìœ \", \"description\": \"ëŒ€í•™ìƒ ì¼ìƒì˜ ë³´í¸ì  ê²½í—˜ì„ ê³µìœ í•˜ì—¬ ê³µê° íšë“\"},\n",
        "                {\"factor_name\": \"ë…¼ë€_ì´ìŠˆ\", \"description\": \"ì˜ê²¬ì´ ê°ˆë¦¬ëŠ” ì£¼ì œë¡œ í† ë¡ ì„ ìœ ë°œ\"},\n",
        "            ]\n",
        "        }\n",
        "        print(\"âš ï¸ ì œì•ˆ ì‹¤íŒ¨, ê¸°ë³¸ íŒ©í„° ì‚¬ìš©\")\n",
        "\n",
        "    factors_data = proposed_factors  # ì´ˆê¸°í™”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKabrrhD87C6"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ PAS Step 2: Assign (í”¼ì²˜ â†’ íŒ©í„° í• ë‹¹) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# ëŒ€ëŸ‰ì˜ í”¼ì²˜ë¥¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬\n",
        "factor_names = [f[\"factor_name\"] for f in factors_data[\"factors\"]]\n",
        "factor_descriptions = {\n",
        "    f[\"factor_name\"]: f.get(\"description\", \"\")\n",
        "    for f in factors_data[\"factors\"]\n",
        "}\n",
        "\n",
        "# ì´ë¯¸ í• ë‹¹ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ\n",
        "if \"assignments\" not in factors_data:\n",
        "    factors_data[\"assignments\"] = {}  # post_key -> [{feature_name, factor}]\n",
        "\n",
        "BATCH_SIZE = 20\n",
        "unassigned_posts = [\n",
        "    pk for pk in all_features.keys()\n",
        "    if pk not in factors_data.get(\"assignments\", {})\n",
        "]\n",
        "print(f\"ğŸ“ í• ë‹¹ ëŒ€ìƒ: {len(unassigned_posts):,}ê±´\")\n",
        "\n",
        "factor_list_str = \"\\n\".join(\n",
        "    f\"{i+1}. {name}: {factor_descriptions[name][:60]}\"\n",
        "    for i, name in enumerate(factor_names)\n",
        ")\n",
        "\n",
        "for batch_start in tqdm(range(0, len(unassigned_posts), BATCH_SIZE), desc=\"íŒ©í„° í• ë‹¹\"):\n",
        "    batch_keys = unassigned_posts[batch_start:batch_start + BATCH_SIZE]\n",
        "\n",
        "    for post_key in batch_keys:\n",
        "        features = all_features[post_key].get(\"features\", [])\n",
        "        if not features:\n",
        "            factors_data[\"assignments\"][post_key] = []\n",
        "            continue\n",
        "\n",
        "        features_str = \"\\n\".join(\n",
        "            f\"  {i+1}. {f['feature_name']}: {f.get('context', '')[:60]}\"\n",
        "            for i, f in enumerate(features)\n",
        "        )\n",
        "\n",
        "        assign_prompt = f\"\"\"\n",
        "ë‹¤ìŒ í”¼ì²˜ë“¤ì„ ê°€ì¥ ì í•©í•œ íŒ©í„°ì— í• ë‹¹í•˜ì„¸ìš”.\n",
        "\n",
        "[ì‚¬ìš© ê°€ëŠ¥í•œ íŒ©í„°]\n",
        "{factor_list_str}\n",
        "\n",
        "[í• ë‹¹í•  í”¼ì²˜ë“¤]\n",
        "{features_str}\n",
        "\n",
        "ê° í”¼ì²˜ì— ëŒ€í•´ ê°€ì¥ ì í•©í•œ íŒ©í„° ì´ë¦„ì„ í• ë‹¹í•˜ì—¬ ë‹¤ìŒ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:\n",
        "{{\n",
        "  \"assignments\": [\n",
        "    {{\"feature_name\": \"...\", \"factor\": \"í• ë‹¹ëœ íŒ©í„° ì´ë¦„\"}},\n",
        "    ...\n",
        "  ]\n",
        "}}\n",
        "\"\"\"\n",
        "        resp = call_gemini(assign_prompt)\n",
        "        parsed = parse_json_response(resp)\n",
        "\n",
        "        if parsed and \"assignments\" in parsed:\n",
        "            factors_data[\"assignments\"][post_key] = parsed[\"assignments\"]\n",
        "        else:\n",
        "            # ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ íŒ©í„°ì— í• ë‹¹\n",
        "            factors_data[\"assignments\"][post_key] = [\n",
        "                {\"feature_name\": f[\"feature_name\"], \"factor\": factor_names[0]}\n",
        "                for f in features\n",
        "            ]\n",
        "\n",
        "        time.sleep(0.3)\n",
        "\n",
        "    # ë°°ì¹˜ ë‹¨ìœ„ ì¤‘ê°„ ì €ì¥\n",
        "    with open(FACTORS_CACHE, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(factors_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\nâœ… íŒ©í„° í• ë‹¹ ì™„ë£Œ â†’ {FACTORS_CACHE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8MZx9Rq87C6"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ íŒ©í„° í†µê³„ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# RPM ë…¼ë¬¸: coverage, influence_rate ë“± í†µê³„ ë¶€ì—¬\n",
        "factor_stats = {name: {\"count\": 0, \"posts\": set()} for name in factor_names}\n",
        "\n",
        "for post_key, assignments in factors_data.get(\"assignments\", {}).items():\n",
        "    for a in assignments:\n",
        "        factor = a.get(\"factor\", \"\")\n",
        "        if factor in factor_stats:\n",
        "            factor_stats[factor][\"count\"] += 1\n",
        "            factor_stats[factor][\"posts\"].add(post_key)\n",
        "\n",
        "total_posts = len(all_features)\n",
        "print(\"\\nğŸ“Š íŒ©í„° í†µê³„:\")\n",
        "print(f\"{'íŒ©í„°':<20} {'í”¼ì²˜ìˆ˜':>8} {'ì»¤ë²„ë¦¬ì§€':>10} {'ê²Œì‹œê¸€ìˆ˜':>10}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for name in factor_names:\n",
        "    stats = factor_stats[name]\n",
        "    coverage = len(stats[\"posts\"]) / max(total_posts, 1)\n",
        "    factor_stats[name][\"coverage\"] = round(coverage, 3)\n",
        "    factor_stats[name][\"post_count\"] = len(stats[\"posts\"])\n",
        "    # setì€ JSON ì €ì¥ ë¶ˆê°€í•˜ë¯€ë¡œ ì œê±°\n",
        "    factor_stats[name][\"posts\"] = list(stats[\"posts\"])[:10]  # ëŒ€í‘œ ê²Œì‹œê¸€ë§Œ\n",
        "    print(f\"{name:<20} {stats['count']:>8} {coverage:>10.1%} {stats['post_count']:>10}\")\n",
        "\n",
        "# íŒ©í„° í†µê³„ë¥¼ factors_dataì— ì¶”ê°€\n",
        "factors_data[\"factor_stats\"] = {\n",
        "    name: {k: v for k, v in stats.items() if k != \"posts\"}\n",
        "    for name, stats in factor_stats.items()\n",
        "}\n",
        "\n",
        "with open(FACTORS_CACHE, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(factors_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\nâœ… íŒ©í„° í†µê³„ ì €ì¥ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "132CIK8p87C6"
      },
      "source": [
        "---\n",
        "## 4. RPM Step 3: Personalized Reasoning Path (ì¶”ë¡ ê²½ë¡œ ìƒì„± = CoT)\n",
        "\n",
        "ê° ì¸ê¸°ê¸€ì— ëŒ€í•´ í”¼ì²˜ì™€ íŒ©í„° ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ\n",
        "**\"ì™œ ì´ ê¸€ì´ ì¸ê¸°ì¸ì§€\"ë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ ì¶”ë¡ í•˜ëŠ” ê²½ë¡œ**ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "RPM ë…¼ë¬¸ Section 3.3ì˜ `r_qi = M(qi, G_qi, C_u, ai)`ì— í•´ë‹¹í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajrAprPt87C7"
      },
      "outputs": [],
      "source": [
        "REASONING_PROMPT = \"\"\"\n",
        "ë‹¹ì‹ ì€ ëŒ€í•™ ì»¤ë®¤ë‹ˆí‹° ì¸ê¸°ê¸€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
        "\n",
        "ë‹¤ìŒ ì¸ê¸°ê¸€ì˜ í”¼ì²˜ì™€ íŒ©í„° ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ,\n",
        "ì´ ê¸€ì´ ì¸ê¸°ë¥¼ ì–»ê²Œ ëœ ì´ìœ ë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ ì¶”ë¡ í•˜ì„¸ìš”.\n",
        "\n",
        "[ê²Œì‹œíŒ] {board}\n",
        "[ì œëª©] {title}\n",
        "[ë‚´ìš© ìš”ì•½] {contents_summary}\n",
        "\n",
        "[ì¶”ì¶œëœ í”¼ì²˜]\n",
        "{features_str}\n",
        "\n",
        "[í•´ë‹¹ íŒ©í„°]\n",
        "{factor_str}\n",
        "\n",
        "ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬, ì´ ê¸€ì„ ì‘ì„±í•  ë•Œ ì–´ë–¤ ì „ëµì„ ì‚¬ìš©í•˜ë©´\n",
        "ì¸ê¸°ê¸€ì´ ë  ìˆ˜ ìˆëŠ”ì§€ 2~3ë¬¸ì¥ìœ¼ë¡œ ì¶”ë¡ í•˜ì„¸ìš”.\n",
        "\"ì™œ ì´ëŸ° ìš”ì†Œê°€ íš¨ê³¼ì ì¸ì§€\" + \"ê¸€ì„ ì“¸ ë•Œì˜ ì „ëµì  ì ‘ê·¼\"ì„ í¬í•¨í•˜ì„¸ìš”.\n",
        "\n",
        "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:\n",
        "{{\"reasoning\": \"ì¶”ë¡  ë‚´ìš©\"}}\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ… Reasoning Path í”„ë¡¬í”„íŠ¸ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw9Aotpv87C7"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ ì¶”ë¡ ê²½ë¡œ ìƒì„± ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "REASONING_CACHE = OUTPUT_DIR / \"rpm_reasoning_paths.json\"\n",
        "\n",
        "if REASONING_CACHE.exists():\n",
        "    with open(REASONING_CACHE, \"r\", encoding=\"utf-8\") as f:\n",
        "        reasoning_paths = json.load(f)\n",
        "    print(f\"âœ… ìºì‹œì—ì„œ ì¶”ë¡ ê²½ë¡œ ë¡œë“œ: {len(reasoning_paths)}ê±´\")\n",
        "else:\n",
        "    reasoning_paths = {}\n",
        "\n",
        "remaining_keys = [\n",
        "    pk for pk in all_features.keys()\n",
        "    if pk not in reasoning_paths\n",
        "]\n",
        "print(f\"ğŸ“ ì¶”ë¡ ê²½ë¡œ ìƒì„± ëŒ€ìƒ: {len(remaining_keys):,}ê±´\")\n",
        "\n",
        "for idx, post_key in enumerate(tqdm(remaining_keys, desc=\"ì¶”ë¡ ê²½ë¡œ ìƒì„±\")):\n",
        "    row_match = hot_df[hot_df[\"post_key\"].astype(str) == post_key]\n",
        "    if row_match.empty:\n",
        "        continue\n",
        "    row = row_match.iloc[0]\n",
        "\n",
        "    title = str(row.get(\"title\", \"\")).strip()\n",
        "    contents = str(row.get(\"contents\", \"\")).strip()\n",
        "    contents_summary = contents[:300]  # ìš”ì•½\n",
        "    board = str(row.get(\"board\", \"\")).strip()\n",
        "\n",
        "    # í”¼ì²˜ ë¬¸ìì—´\n",
        "    features = all_features.get(post_key, {}).get(\"features\", [])\n",
        "    features_str = \"\\n\".join(\n",
        "        f\"- {f['feature_name']}: {f.get('context', '')[:60]}\"\n",
        "        for f in features\n",
        "    )\n",
        "\n",
        "    # íŒ©í„° ì •ë³´\n",
        "    assignments = factors_data.get(\"assignments\", {}).get(post_key, [])\n",
        "    assigned_factors = list(set(a.get(\"factor\", \"\") for a in assignments if a.get(\"factor\")))\n",
        "    factor_str = \", \".join(assigned_factors) if assigned_factors else \"ì¼ë°˜\"\n",
        "\n",
        "    prompt = REASONING_PROMPT.format(\n",
        "        board=board, title=title, contents_summary=contents_summary,\n",
        "        features_str=features_str, factor_str=factor_str\n",
        "    )\n",
        "\n",
        "    resp = call_gemini(prompt)\n",
        "    parsed = parse_json_response(resp)\n",
        "\n",
        "    if parsed and \"reasoning\" in parsed:\n",
        "        reasoning_paths[post_key] = {\n",
        "            \"reasoning\": parsed[\"reasoning\"],\n",
        "            \"factors\": assigned_factors,\n",
        "        }\n",
        "    else:\n",
        "        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
        "        reasoning_paths[post_key] = {\n",
        "            \"reasoning\": resp[:300] if resp else f\"{factor_str} íŒ©í„°ì— í•´ë‹¹í•˜ëŠ” ì¸ê¸°ê¸€ì…ë‹ˆë‹¤.\",\n",
        "            \"factors\": assigned_factors,\n",
        "        }\n",
        "\n",
        "    # ì£¼ê¸°ì  ì €ì¥\n",
        "    if (idx + 1) % SAVE_INTERVAL == 0:\n",
        "        with open(REASONING_CACHE, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(reasoning_paths, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"  ğŸ’¾ ì¤‘ê°„ ì €ì¥ ({len(reasoning_paths)}ê±´)\")\n",
        "\n",
        "    time.sleep(0.3)\n",
        "\n",
        "# ìµœì¢… ì €ì¥\n",
        "with open(REASONING_CACHE, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(reasoning_paths, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\nâœ… ì¶”ë¡ ê²½ë¡œ ìƒì„± ì™„ë£Œ: {len(reasoning_paths)}ê±´ â†’ {REASONING_CACHE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOm0AKRe87C7"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ ì¶”ë¡ ê²½ë¡œ ìƒ˜í”Œ í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "sample_keys = list(reasoning_paths.keys())[:3]\n",
        "for key in sample_keys:\n",
        "    row = hot_df[hot_df[\"post_key\"].astype(str) == key]\n",
        "    if row.empty:\n",
        "        continue\n",
        "    row = row.iloc[0]\n",
        "    rp = reasoning_paths[key]\n",
        "    print(f\"\\nğŸ“ [{row['board']}] {row['title'][:50]}\")\n",
        "    print(f\"  íŒ©í„°: {', '.join(rp['factors'])}\")\n",
        "    print(f\"  ì¶”ë¡ : {rp['reasoning'][:150]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k09BRPa387C7"
      },
      "source": [
        "---\n",
        "## 5. í‚¤ì›Œë“œ ì¶”ì¶œ (ê¸°ì¡´ Phase 2 í˜¸í™˜)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1ztnTAu87C7"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "DEFAULT_STOPWORDS = [\n",
        "    \"ì´\",\"ê°€\",\"ì„\",\"ë¥¼\",\"ì—\",\"ì˜\",\"ì™€\",\"ê³¼\",\"ë„\",\"ë¡œ\",\"ìœ¼ë¡œ\",\n",
        "    \"ì€\",\"ëŠ”\",\"ì—ì„œ\",\"ì—ê²Œ\",\"ê»˜\",\"í•œí…Œ\",\n",
        "    \"ë”\",\"ê·¸\",\"ì €\",\"ì´ê²ƒ\",\"ê·¸ê²ƒ\",\"ì €ê²ƒ\",\"ê·¸ëŸ°\",\"ì´ëŸ°\",\"ì €ëŸ°\",\n",
        "    \"ë•Œ\",\"ë•Œë¬¸\",\"ê²ƒ\",\"ìˆ˜\",\"ë“±\",\n",
        "    \"ìˆë‹¤\",\"ì—†ë‹¤\",\"í•˜ë‹¤\",\"ë˜ë‹¤\",\"ì´ë‹¤\",\"ì•„ë‹ˆë‹¤\",\"ê°™ë‹¤\",\n",
        "    \"ê²Œì‹œíŒ\",\"ê²Œì‹œê¸€\",\"ê¸€\",\"ëŒ“ê¸€\",\"ì‘ì„±\",\"ì‘ì„±ì\",\"ì¡°íšŒ\",\"ì¶”ì²œ\",\"ë¹„ì¶”ì²œ\",\n",
        "    \"nan\", \"NaN\", \"None\",\n",
        "]\n",
        "CUSTOM_STOPWORDS = set(DEFAULT_STOPWORDS)\n",
        "\n",
        "\n",
        "def extract_keywords_simple(text: str, top_k: int = 8, min_len: int = 2) -> list:\n",
        "    \"\"\"ê°„ë‹¨í•œ ì •ê·œì‹ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ (Mecab ë¶ˆí•„ìš”)\"\"\"\n",
        "    if pd.isna(text) or not text:\n",
        "        return []\n",
        "    tokens = re.findall(r\"[ê°€-í£a-zA-Z0-9]+\", text)\n",
        "    filtered = [tok for tok in tokens if tok not in CUSTOM_STOPWORDS and len(tok) >= min_len]\n",
        "    counts = Counter(filtered)\n",
        "    return [token for token, _ in counts.most_common(top_k)]\n",
        "\n",
        "\n",
        "# í‚¤ì›Œë“œ ì¶”ì¶œ\n",
        "hot_df[\"keyword_list\"] = (\n",
        "    hot_df[\"title\"].fillna(\"\") + \" \" + hot_df[\"contents\"].fillna(\"\")\n",
        ").apply(lambda x: extract_keywords_simple(x, top_k=8))\n",
        "hot_df[\"keywords\"] = hot_df[\"keyword_list\"].apply(lambda ks: \", \".join(ks))\n",
        "\n",
        "print(\"âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ\")\n",
        "print(\"ìƒ˜í”Œ:\")\n",
        "display(hot_df[[\"title\", \"keywords\"]].head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82npmVu087C7"
      },
      "source": [
        "---\n",
        "## 6. ìµœì¢… í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± (SOS/EOS + CoT í†µí•©)\n",
        "\n",
        "ëª¨ë“  RPM ê²°ê³¼ë¬¼ì„ í†µí•©í•˜ì—¬ SOS/EOS í† í°ì´ í¬í•¨ëœ\n",
        "`training_dataset_v2.jsonl`ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "### í•™ìŠµ ë°ì´í„° í¬ë§·\n",
        "```\n",
        "<|begin_of_text|>Below is an instruction...\n",
        "\n",
        "### Instruction:\n",
        "ì£¼ì–´ì§„ í‚¤ì›Œë“œì™€ ì¸ê¸°ìš”ì¸ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ {board}ì˜ ì¸ê¸°ê¸€ ìŠ¤íƒ€ì¼ë¡œ ê¸€ì„ ì‘ì„±í•´ì¤˜.\n",
        "\n",
        "### Input:\n",
        "í‚¤ì›Œë“œ: ...\n",
        "ì¸ê¸°ìš”ì¸: ... (ì»¤ë²„ë¦¬ì§€: ..., ì˜í–¥ë„: ...)\n",
        "\n",
        "### Thinking:\n",
        "{reasoning_path}\n",
        "\n",
        "### Response:\n",
        "{title}\\n\\n{contents}<|end_of_text|>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fap6ZKbD87C7"
      },
      "outputs": [],
      "source": [
        "def build_training_record(\n",
        "    row: pd.Series,\n",
        "    reasoning_paths: dict,\n",
        "    factors_data: dict,\n",
        ") -> dict | None:\n",
        "    \"\"\"\n",
        "    í•œ ê±´ì˜ í•™ìŠµ ë ˆì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "    RPM(í”¼ì²˜/íŒ©í„°/ì¶”ë¡ ê²½ë¡œ) + CoT + SOS/EOS í†µí•©.\n",
        "    \"\"\"\n",
        "    post_key = str(row.get(\"post_key\", \"\"))\n",
        "    keywords = row.get(\"keyword_list\", [])\n",
        "    if not keywords:\n",
        "        return None\n",
        "\n",
        "    board = str(row.get(\"board\", \"ë¯¸ìƒ\")).strip()\n",
        "    title = str(row.get(\"title\", \"\")).strip()\n",
        "    contents = str(row.get(\"contents\", \"\")).strip()\n",
        "    full_text = f\"{title}\\n\\n{contents}\".strip()\n",
        "    if not full_text or full_text == \"nan\":\n",
        "        return None\n",
        "\n",
        "    # â”€â”€ íŒ©í„° ì •ë³´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    rp_data = reasoning_paths.get(post_key, {})\n",
        "    assigned_factors = rp_data.get(\"factors\", [])\n",
        "    reasoning = rp_data.get(\"reasoning\", \"\")\n",
        "\n",
        "    # íŒ©í„° í†µê³„\n",
        "    factor_stats = factors_data.get(\"factor_stats\", {})\n",
        "    if assigned_factors:\n",
        "        primary_factor = assigned_factors[0]\n",
        "        stats = factor_stats.get(primary_factor, {})\n",
        "        coverage = stats.get(\"coverage\", 0)\n",
        "        factor_info = f\"{primary_factor} (ì»¤ë²„ë¦¬ì§€: {coverage:.0%})\"\n",
        "    else:\n",
        "        factor_info = \"ì¼ë°˜\"\n",
        "\n",
        "    # â”€â”€ Instruction / Input / Thinking / Output â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    instruction = f\"ì£¼ì–´ì§„ í‚¤ì›Œë“œì™€ ì¸ê¸°ìš”ì¸ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ {board}ì˜ ì¸ê¸°ê¸€ ìŠ¤íƒ€ì¼ë¡œ ê¸€ì„ ì‘ì„±í•´ì¤˜.\"\n",
        "    input_text = f\"í‚¤ì›Œë“œ: {', '.join(keywords)}\\nì¸ê¸°ìš”ì¸: {factor_info}\"\n",
        "\n",
        "    # CoT (Thinking) - ì¶”ë¡ ê²½ë¡œ\n",
        "    thinking = reasoning if reasoning else f\"{factor_info}ì— í•´ë‹¹í•˜ëŠ” ì¸ê¸°ê¸€ì„ ì‘ì„±í•©ë‹ˆë‹¤.\"\n",
        "\n",
        "    return {\n",
        "        \"instruction\": instruction,\n",
        "        \"input\": input_text,\n",
        "        \"thinking\": thinking,\n",
        "        \"output\": full_text,\n",
        "        \"post_key\": post_key,\n",
        "        \"board\": board,\n",
        "        \"factors\": assigned_factors,\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"âœ… ë ˆì½”ë“œ ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8Nm0PKs87C8"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ ì „ì²´ ë°ì´í„°ì…‹ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"ğŸ”§ í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...\\n\")\n",
        "\n",
        "records = []\n",
        "skipped = 0\n",
        "\n",
        "for _, row in tqdm(hot_df.iterrows(), total=len(hot_df), desc=\"ë°ì´í„°ì…‹ ìƒì„±\"):\n",
        "    record = build_training_record(row, reasoning_paths, factors_data)\n",
        "    if record:\n",
        "        records.append(record)\n",
        "    else:\n",
        "        skipped += 1\n",
        "\n",
        "print(f\"\\nâœ… ìƒì„± ì™„ë£Œ: {len(records):,}ê±´ (ìŠ¤í‚µ: {skipped:,}ê±´)\")\n",
        "\n",
        "# â”€â”€ ê²Œì‹œíŒë³„ ë¶„í¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "board_dist = Counter(r[\"board\"] for r in records)\n",
        "print(\"\\nğŸ“Š ê²Œì‹œíŒë³„ ë¶„í¬:\")\n",
        "for board, count in board_dist.most_common():\n",
        "    print(f\"  {board}: {count:,}ê±´\")\n",
        "\n",
        "# â”€â”€ íŒ©í„°ë³„ ë¶„í¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "factor_dist = Counter(\n",
        "    f for r in records for f in r.get(\"factors\", [\"ì—†ìŒ\"])\n",
        ")\n",
        "print(\"\\nğŸ“Š íŒ©í„°ë³„ ë¶„í¬:\")\n",
        "for factor, count in factor_dist.most_common():\n",
        "    print(f\"  {factor}: {count:,}ê±´\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlKuSsd187C8"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ SOS/EOS í¬í•¨ëœ ìµœì¢… JSONL ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# ì°¸ê³ : SOS/EOS í† í°ì€ Phase 3ì—ì„œ í† í¬ë‚˜ì´ì € ë¡œë“œ í›„\n",
        "#       ì‹¤ì œ í† í°ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” placeholderë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.\n",
        "\n",
        "BOS = \"<|begin_of_text|>\"\n",
        "EOS = \"<|end_of_text|>\"\n",
        "\n",
        "jsonl_path = OUTPUT_DIR / \"training_dataset_v2.jsonl\"\n",
        "\n",
        "with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for record in records:\n",
        "        # í•™ìŠµìš© text í•„ë“œ (Phase 3ì—ì„œ ì§ì ‘ ì‚¬ìš©)\n",
        "        text = (\n",
        "            f\"{BOS}Below is an instruction that describes a task. \"\n",
        "            f\"Write a response that appropriately completes the request.\\n\\n\"\n",
        "            f\"### Instruction:\\n{record['instruction']}\\n\\n\"\n",
        "            f\"### Input:\\n{record['input']}\\n\\n\"\n",
        "            f\"### Thinking:\\n{record['thinking']}\\n\\n\"\n",
        "            f\"### Response:\\n{record['output']}{EOS}\"\n",
        "        )\n",
        "\n",
        "        jsonl_record = {\n",
        "            \"instruction\": record[\"instruction\"],\n",
        "            \"input\": record[\"input\"],\n",
        "            \"thinking\": record[\"thinking\"],\n",
        "            \"output\": record[\"output\"],\n",
        "            \"text\": text,\n",
        "        }\n",
        "        f.write(json.dumps(jsonl_record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"âœ… í•™ìŠµ ë°ì´í„°ì…‹ ì €ì¥ ì™„ë£Œ: {len(records):,}ê±´ â†’ {jsonl_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMbPFHPz87C8"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ ìƒ˜í”Œ í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ìƒ˜í”Œ ë ˆì½”ë“œ (ìµœëŒ€ 3ê±´)\".center(70))\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for i, rec in enumerate(records[:3], 1):\n",
        "    print(f\"\\n[{i}] ê²Œì‹œíŒ: {rec['board']} | íŒ©í„°: {', '.join(rec['factors'])}\")\n",
        "    print(f\"  Instruction: {rec['instruction'][:80]}\")\n",
        "    print(f\"  Input: {rec['input'][:80]}\")\n",
        "    print(f\"  Thinking: {rec['thinking'][:120]}...\")\n",
        "    print(f\"  Output: {rec['output'][:120]}...\")\n",
        "    print(\"-\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9Ouj5c987C8"
      },
      "source": [
        "---\n",
        "## 7. ì™„ë£Œ ë° ë‹¤ìŒ ë‹¨ê³„\n",
        "\n",
        "### ìƒì„±ëœ íŒŒì¼\n",
        "| íŒŒì¼ | ì„¤ëª… |\n",
        "|------|------|\n",
        "| `rpm_features.json` | RPM Step 1: ê° ê²Œì‹œê¸€ì˜ ì¸ê¸° ê¸°ì—¬ í”¼ì²˜ |\n",
        "| `rpm_factors.json` | RPM Step 2: íŒ©í„°(í´ëŸ¬ìŠ¤í„°) + í• ë‹¹ + í†µê³„ |\n",
        "| `rpm_reasoning_paths.json` | RPM Step 3: ì¶”ë¡ ê²½ë¡œ (= CoT) |\n",
        "| `training_dataset_v2.jsonl` | ìµœì¢… í•™ìŠµ ë°ì´í„°ì…‹ (SOS/EOS + CoT í¬í•¨) |\n",
        "\n",
        "### ë‹¤ìŒ ë‹¨ê³„\n",
        "â†’ `phase3_finetune_v2.ipynb`ì—ì„œ QLoRA í•™ìŠµ ì§„í–‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Od01AQgC87C8"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Phase 2v2 ì™„ë£Œ - RPM ê¸°ë°˜ ê³ ë„í™” ë°ì´í„°ì…‹ ìš”ì•½\".center(70))\n",
        "print(\"=\" * 70)\n",
        "print(f\"  ì „ì²´ ì¸ê¸°ê¸€:   {len(hot_df):,}ê±´\")\n",
        "print(f\"  ì¶”ì¶œ í”¼ì²˜:     {len(all_features):,}ê±´\")\n",
        "print(f\"  íŒ©í„° ìˆ˜:       {len(factor_names)}ê°œ\")\n",
        "print(f\"  ì¶”ë¡ ê²½ë¡œ:      {len(reasoning_paths):,}ê±´\")\n",
        "print(f\"  í•™ìŠµ ë°ì´í„°ì…‹: {len(records):,}ê±´\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nğŸ‰ Phase 2v2 ì™„ë£Œ!\")\n",
        "print(\"ë‹¤ìŒ ë‹¨ê³„: phase3_finetune_v2.ipynb\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}