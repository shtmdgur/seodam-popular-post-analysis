{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fV61v7Kwd5Q"
      },
      "source": [
        "# Phase 5: Gemini API ê¸°ë°˜ ì¸ê¸°ê¸€ ìƒì„±\n",
        "\n",
        "## ğŸ“Œ ëª©ì \n",
        "Phase 2ì—ì„œ ì¶”ì¶œí•œ **íŒ©í„°(ì¸ê¸°ìœ í˜•)**, **í”¼ì²˜(ì¸ê¸°ìš”ì†Œ)**, **í‚¤ì›Œë“œ** ì •ë³´ë¥¼\n",
        "Gemini API í”„ë¡¬í”„íŠ¸ì— í†µí•©í•˜ì—¬ ì„œë‹´ ìŠ¤íƒ€ì¼ ì¸ê¸°ê¸€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "### í•µì‹¬ êµ¬ì¡°\n",
        "```\n",
        "íŒ©í„°(ê°ì •ì _ê³µê° ë“±) + í”¼ì²˜(ì‹¤ì œ ì¸ê¸°ê¸€ íŒ¨í„´) + í‚¤ì›Œë“œ\n",
        "  â†’ Gemini í”„ë¡¬í”„íŠ¸ â†’ Thinking(ì „ëµ) â†’ Title + Content\n",
        "```\n",
        "\n",
        "### ì‚¬ì „ ì¡°ê±´\n",
        "- `phase2_dataset_v2.ipynb` ì‹¤í–‰ ì™„ë£Œ\n",
        "- Colab Secretsì— `GEMINI_API_KEY` ë“±ë¡\n",
        "- GPU **ë¶ˆí•„ìš”** (API ê¸°ë°˜)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxCggjZjwd5V"
      },
      "source": [
        "---\n",
        "## 0. í™˜ê²½ ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiSRk2LBwd5W"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive, userdata\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import google.generativeai as genai\n",
        "import json, time, re\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# â”€â”€ Gemini API ì—°ê²° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "gemini_model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "print(\"âœ… Gemini API ì—°ê²° ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGW87ahowd5Y"
      },
      "source": [
        "---\n",
        "## 1. RPM ë°ì´í„° ë¡œë“œ (íŒ©í„° + í”¼ì²˜ + í‚¤ì›Œë“œ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX8ytXa2wd5Y"
      },
      "outputs": [],
      "source": [
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/board_crawling\")\n",
        "OUTPUT_DIR   = PROJECT_ROOT / \"outputs\"\n",
        "\n",
        "# â”€â”€ íŒ©í„° ì •ë³´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "FACTORS_PATH = OUTPUT_DIR / \"rpm_factors.json\"\n",
        "if FACTORS_PATH.exists():\n",
        "    with open(FACTORS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        factors_data = json.load(f)\n",
        "    factor_names = [f[\"factor_name\"] for f in factors_data[\"factors\"]]\n",
        "    factor_descriptions = {\n",
        "        f[\"factor_name\"]: f.get(\"description\", \"\")\n",
        "        for f in factors_data[\"factors\"]\n",
        "    }\n",
        "    factor_stats = factors_data.get(\"factor_stats\", {})\n",
        "    print(f\"âœ… íŒ©í„° ë¡œë“œ: {len(factor_names)}ê°œ\")\n",
        "    for name in factor_names:\n",
        "        cov = factor_stats.get(name, {}).get(\"coverage\", 0)\n",
        "        print(f\"  â†’ {name} (ì»¤ë²„ë¦¬ì§€: {cov:.0%}): {factor_descriptions.get(name, '')[:50]}\")\n",
        "else:\n",
        "    factor_names = [\"ê°ì •ì _ê³µê°\", \"ìœ ë¨¸_ë°˜ì „\", \"ì •ë³´_ì „ë‹¬\", \"ì°¸ì—¬_ìœ ë„\", \"ì¼ìƒ_ê³µìœ \", \"ë…¼ë€_ì´ìŠˆ\"]\n",
        "    factor_descriptions = {\n",
        "        \"ê°ì •ì _ê³µê°\": \"ë…ìì˜ ê°ì •ì  ê³µê°ì„ ìœ ë°œí•˜ëŠ” ë‚´ìš©ì´ë‚˜ ì–´íˆ¬\",\n",
        "        \"ìœ ë¨¸_ë°˜ì „\": \"ì›ƒìŒì„ ìœ ë°œí•˜ëŠ” ìœ ë¨¸ëŸ¬ìŠ¤í•œ ë‚´ìš©ì´ë‚˜ ë°˜ì „ ìš”ì†Œ\",\n",
        "        \"ì •ë³´_ì „ë‹¬\": \"ìœ ìš©í•œ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” êµ¬ì¡°ë‚˜ ë‚´ìš©\",\n",
        "        \"ì°¸ì—¬_ìœ ë„\": \"ì§ˆë¬¸/íˆ¬í‘œ ë“±ìœ¼ë¡œ ë…ìì˜ ì ê·¹ì  ì°¸ì—¬ë¥¼ ìœ ë„\",\n",
        "        \"ì¼ìƒ_ê³µìœ \": \"ëŒ€í•™ìƒ ì¼ìƒì˜ ë³´í¸ì  ê²½í—˜ì„ ê³µìœ í•˜ì—¬ ê³µê° íšë“\",\n",
        "        \"ë…¼ë€_ì´ìŠˆ\": \"ì˜ê²¬ì´ ê°ˆë¦¬ëŠ” ì£¼ì œë¡œ í† ë¡ ì„ ìœ ë°œ\",\n",
        "    }\n",
        "    factor_stats = {}\n",
        "    print(\"âš ï¸ íŒ©í„° íŒŒì¼ ì—†ìŒ â†’ ê¸°ë³¸ 6ê°œ íŒ©í„° ì‚¬ìš©\")\n",
        "\n",
        "# â”€â”€ í”¼ì²˜ ì •ë³´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "FEATURES_PATH = OUTPUT_DIR / \"rpm_features.json\"\n",
        "if FEATURES_PATH.exists():\n",
        "    with open(FEATURES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        all_features = json.load(f)\n",
        "    # ì˜ë¯¸ ìˆëŠ” í”¼ì²˜ë§Œ í•„í„°ë§ (ê¸°ë³¸ê°’ 'ë‚´ìš©_êµ¬ì„±' ì œì™¸)\n",
        "    good_features = []\n",
        "    for pk, data in all_features.items():\n",
        "        for feat in data.get(\"features\", []):\n",
        "            fn = feat.get(\"feature_name\", feat.get(\"name\", \"\"))\n",
        "            ctx = feat.get(\"context\", \"\")\n",
        "            if fn and fn != \"ë‚´ìš©_êµ¬ì„±\" and len(ctx) > 10:\n",
        "                good_features.append({\"name\": fn, \"context\": ctx[:80]})\n",
        "    print(f\"âœ… í”¼ì²˜ ë¡œë“œ: ì „ì²´ {len(all_features)}ê±´ ì¤‘ ì˜ë¯¸ ìˆëŠ” í”¼ì²˜ {len(good_features)}ê°œ\")\n",
        "else:\n",
        "    all_features = {}\n",
        "    good_features = []\n",
        "    print(\"âš ï¸ í”¼ì²˜ íŒŒì¼ ì—†ìŒ\")\n",
        "\n",
        "# â”€â”€ í† í”½ í‚¤ì›Œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "PROMPT_FILES = {\n",
        "    \"ìµê²Œ2\":     OUTPUT_DIR / \"ìµê²Œ2_topics_for_prompt.json\",\n",
        "    \"ììœ ê²Œì‹œíŒ\": OUTPUT_DIR / \"ììœ ê²Œì‹œíŒ_topics_for_prompt.json\",\n",
        "    \"ì—°ì• ìƒë‹´ì†Œ\": OUTPUT_DIR / \"ì—°ì• ìƒë‹´ì†Œ_topics_for_prompt.json\",\n",
        "    \"ìµê²Œ1\":     OUTPUT_DIR / \"ìµê²Œ1_topics_for_prompt.json\",\n",
        "}\n",
        "\n",
        "trend_keywords = {}\n",
        "for board, path in PROMPT_FILES.items():\n",
        "    if not path.exists():\n",
        "        print(f\"âš ï¸ {board}: íŒŒì¼ ì—†ìŒ â†’ ê±´ë„ˆëœ€\")\n",
        "        continue\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        topics_data = json.load(f)\n",
        "    top_topics = sorted(\n",
        "        topics_data,\n",
        "        key=lambda x: len(x.get(\"representatives\", [])),\n",
        "        reverse=True\n",
        "    )[:5]\n",
        "    keywords = []\n",
        "    for topic in top_topics:\n",
        "        kw = topic.get(\"keywords\", [])\n",
        "        if isinstance(kw, list):\n",
        "            keywords.extend(kw[:8])\n",
        "    trend_keywords[board] = list(dict.fromkeys(keywords))[:8]\n",
        "    print(f\"âœ… {board}: {trend_keywords[board]}\")\n",
        "\n",
        "if not trend_keywords:\n",
        "    print(\"âš ï¸ í‚¤ì›Œë“œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ë™ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
        "    trend_keywords = {\n",
        "        \"ìµê²Œ2\": [\"ì‹œí—˜\", \"êµìˆ˜\", \"í•™ì \", \"ê³¼ì œ\", \"MT\"],\n",
        "        \"ììœ ê²Œì‹œíŒ\": [\"ì·¨ì—…\", \"ëŒ€í•™ì›\", \"ì¡¸ì—…\", \"ë™ì•„ë¦¬\"],\n",
        "        \"ì—°ì• ìƒë‹´ì†Œ\": [\"ë‚¨ì¹œ\", \"ì—¬ì¹œ\", \"ì´ë³„\", \"ê³ ë°±\", \"ì¸\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH9n636xwd5Z"
      },
      "source": [
        "---\n",
        "## 2. Gemini í—¬í¼ + ìƒì„± í•¨ìˆ˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmzd-3oWwd5a"
      },
      "outputs": [],
      "source": [
        "def call_gemini(prompt: str, temperature: float = 0.7) -> str:\n",
        "    \"\"\"Gemini API í˜¸ì¶œ (ì¬ì‹œë„ í¬í•¨)\"\"\"\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            response = gemini_model.generate_content(\n",
        "                prompt,\n",
        "                generation_config=genai.types.GenerationConfig(\n",
        "                    temperature=temperature,\n",
        "                    max_output_tokens=2048,\n",
        "                ),\n",
        "            )\n",
        "            return response.text.strip()\n",
        "        except Exception as e:\n",
        "            if \"429\" in str(e) or \"rate\" in str(e).lower():\n",
        "                wait = 15 * (attempt + 1)\n",
        "                print(f\"  â³ Rate limit, {wait}ì´ˆ ëŒ€ê¸°\")\n",
        "                time.sleep(wait)\n",
        "            else:\n",
        "                print(f\"  âš ï¸ ì—ëŸ¬: {str(e)[:100]}\")\n",
        "                return \"\"\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "def generate_post_gemini(\n",
        "    board_name: str,\n",
        "    keywords: list,\n",
        "    factor_name: str,\n",
        "    factor_desc: str = \"\",\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Geminië¡œ CoT ê¸°ë°˜ ì¸ê¸°ê¸€ ìƒì„±.\n",
        "    íŒ©í„° + í”¼ì²˜ + í‚¤ì›Œë“œë¥¼ í”„ë¡¬í”„íŠ¸ì— í†µí•©.\n",
        "    \"\"\"\n",
        "    # í”¼ì²˜ ì˜ˆì‹œ ëœë¤ ìƒ˜í”Œ (ë§¤ë²ˆ ë‹¤ë¥¸ ì¡°í•©)\n",
        "    if good_features:\n",
        "        sampled = random.sample(good_features, min(8, len(good_features)))\n",
        "        feature_sample = \"\\n\".join(\n",
        "            f\"  - {f['name']}: {f['context']}\"\n",
        "            for f in sampled\n",
        "        )\n",
        "    else:\n",
        "        feature_sample = \"  (í”¼ì²˜ ë°ì´í„° ì—†ìŒ)\"\n",
        "\n",
        "    prompt = f\"\"\"ë‹¹ì‹ ì€ ì„œê°•ëŒ€í•™êµ ì»¤ë®¤ë‹ˆí‹° 'ì„œë‹´(ì„œê°•ë‹´ë²¼ë½)'ì˜ ì¸ê¸°ê¸€ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ ì¡°ê±´ì— ë§ì¶° ì¸ê¸°ê¸€ì„ ì‘ì„±í•˜ì„¸ìš”.\n",
        "\n",
        "[ê²Œì‹œíŒ] {board_name}\n",
        "[í‚¤ì›Œë“œ] {', '.join(keywords)}\n",
        "[ì¸ê¸° ìš”ì¸ (íŒ©í„°)] {factor_name}: {factor_desc}\n",
        "\n",
        "[ì°¸ê³ : ì‹¤ì œ ì¸ê¸°ê¸€ì—ì„œ ì¶”ì¶œëœ ì¸ê¸° ìš”ì†Œ(í”¼ì²˜) ì˜ˆì‹œ]\n",
        "{feature_sample}\n",
        "\n",
        "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ì— ë§ì¶° ì‘ì„±í•˜ì„¸ìš”:\n",
        "\n",
        "1. <Thinking> íƒœê·¸: \"ì™œ ì´ëŸ° ìš”ì†Œê°€ ì¸ê¸°ë¥¼ ë„ëŠ”ì§€\" + \"ì–´ë–¤ ì „ëµìœ¼ë¡œ ê¸€ì„ ì“¸ì§€\" 2~3ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬\n",
        "2. <Title> íƒœê·¸: í´ë¦­ì„ ìœ ë°œí•˜ëŠ” ì œëª© (ì„œë‹´ íŠ¹ìœ ì˜ ë§íˆ¬ ì‚¬ìš©)\n",
        "3. <Content> íƒœê·¸: ì‹¤ì œ ê²Œì‹œê¸€ ë³¸ë¬¸\n",
        "\n",
        "í•„ìˆ˜ ê·œì¹™:\n",
        "- ì„œë‹´ ëŒ€í•™ìƒ ì»¤ë®¤ë‹ˆí‹° íŠ¹ìœ ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬ë¥¼ ì‚¬ìš©í•  ê²ƒ\n",
        "- í˜•ì‹ì ì´ê±°ë‚˜ AIê°€ ì“´ ê²ƒ ê°™ì€ ë¬¸ì²´ ì ˆëŒ€ ê¸ˆì§€\n",
        "- ì‹¤ì œ ì„œê°•ëŒ€ìƒì´ ì“´ ê²ƒì²˜ëŸ¼ ëŠê»´ì ¸ì•¼ í•¨\n",
        "- ì´ëª¨í‹°ì½˜ì´ë‚˜ íŠ¹ìˆ˜ë¬¸ìëŠ” ìì œí•˜ë˜, ìì—°ìŠ¤ëŸ¬ìš´ ê²½ìš° í—ˆìš©\n",
        "\n",
        "<Thinking>\n",
        "(ì¶”ë¡ )\n",
        "</Thinking>\n",
        "<Title>\n",
        "(ì œëª©)\n",
        "</Title>\n",
        "<Content>\n",
        "(ë³¸ë¬¸)\n",
        "</Content>\n",
        "\"\"\"\n",
        "\n",
        "    result = call_gemini(prompt, temperature=0.8)\n",
        "\n",
        "    # íƒœê·¸ íŒŒì‹±\n",
        "    thinking = re.search(r'<Thinking>(.*?)</Thinking>', result, re.DOTALL)\n",
        "    title    = re.search(r'<Title>(.*?)</Title>', result, re.DOTALL)\n",
        "    content  = re.search(r'<Content>(.*?)</Content>', result, re.DOTALL)\n",
        "\n",
        "    return {\n",
        "        \"board_name\": board_name,\n",
        "        \"keywords\": \", \".join(keywords),\n",
        "        \"factor\": factor_name,\n",
        "        \"thinking\": thinking.group(1).strip() if thinking else \"\",\n",
        "        \"generated_title\": title.group(1).strip() if title else \"\",\n",
        "        \"generated_content\": content.group(1).strip() if content else result[:500],\n",
        "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        \"raw_response\": result,\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"âœ… CoT ê¸°ë°˜ Gemini ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgfC3joEwd5b"
      },
      "source": [
        "---\n",
        "## 3. ê²Œì‹œíŒë³„ + íŒ©í„°ë³„ ìƒì„± ì‹¤í–‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULICPcpjwd5b"
      },
      "outputs": [],
      "source": [
        "generated_posts = []\n",
        "top_factors = factor_names[:3] if len(factor_names) >= 3 else factor_names\n",
        "\n",
        "print(f\"ğŸ“‹ ìƒì„± ê³„íš: {len(trend_keywords)}ê°œ ê²Œì‹œíŒ Ã— {len(top_factors)}ê°œ íŒ©í„° = {len(trend_keywords) * len(top_factors)}ê±´\")\n",
        "print(f\"   íŒ©í„°: {top_factors}\")\n",
        "print(f\"   ê²Œì‹œíŒ: {list(trend_keywords.keys())}\")\n",
        "print()\n",
        "\n",
        "for board, keywords in trend_keywords.items():\n",
        "    if not keywords:\n",
        "        continue\n",
        "\n",
        "    for factor in top_factors:\n",
        "        desc = factor_descriptions.get(factor, \"\")\n",
        "        print(f\"ğŸ”§ ìƒì„± ì¤‘: [{board}] íŒ©í„°={factor}\")\n",
        "\n",
        "        try:\n",
        "            result = generate_post_gemini(board, keywords, factor, desc)\n",
        "            generated_posts.append(result)\n",
        "\n",
        "            print(f\"  ğŸ’­ Thinking: {result['thinking'][:100]}\")\n",
        "            print(f\"  ğŸ“ ì œëª©: {result['generated_title']}\")\n",
        "            print(f\"  ğŸ“„ ë‚´ìš©: {result['generated_content'][:150]}...\")\n",
        "            print()\n",
        "\n",
        "        except Exception as exc:\n",
        "            print(f\"  âš ï¸ ìƒì„± ì‹¤íŒ¨: {exc}\")\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "print(f\"\\nâœ… ì´ {len(generated_posts)}ê±´ ìƒì„± ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLHrTL6vwd5c"
      },
      "source": [
        "---\n",
        "## 4. ê²°ê³¼ ì €ì¥ ë° ìš”ì•½"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LpHY9tJwd5d"
      },
      "outputs": [],
      "source": [
        "if generated_posts:\n",
        "    result_df = pd.DataFrame(generated_posts)\n",
        "    # raw_responseëŠ” CSVì—ì„œ ì œì™¸\n",
        "    save_cols = [c for c in result_df.columns if c != \"raw_response\"]\n",
        "\n",
        "    output_csv = OUTPUT_DIR / \"generated_posts_gemini.csv\"\n",
        "    result_df[save_cols].to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"âœ… CSV ì €ì¥ ì™„ë£Œ: {output_csv}\")\n",
        "\n",
        "    output_json = OUTPUT_DIR / \"generated_posts_gemini.json\"\n",
        "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(generated_posts, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"âœ… JSON ì €ì¥ ì™„ë£Œ: {output_json}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"ìƒì„± ê²°ê³¼ ìš”ì•½\".center(70))\n",
        "    print(\"=\" * 70)\n",
        "    display(result_df[[\"board_name\", \"factor\", \"generated_title\"]])\n",
        "else:\n",
        "    print(\"âš ï¸ ìƒì„±ëœ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS5qAURXwd5d"
      },
      "source": [
        "---\n",
        "## 5. CoT ìƒì„¸ ì¶œë ¥ (Thinking â†’ Response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HWt5inwwd5e"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CoT ìƒì„¸ ì¶œë ¥ (Thinking â†’ Title â†’ Content)\".center(70))\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for i, post in enumerate(generated_posts, 1):\n",
        "    print(f\"\\n{'â”€' * 70}\")\n",
        "    print(f\"[{i}] [{post['board_name']}] íŒ©í„°: {post['factor']}\")\n",
        "    print(f\"    í‚¤ì›Œë“œ: {post['keywords']}\")\n",
        "    print(f\"\\n    ğŸ’­ Thinking:\")\n",
        "    print(f\"    {post['thinking']}\")\n",
        "    print(f\"\\n    ğŸ“ ì œëª©: {post['generated_title']}\")\n",
        "    print(f\"\\n    ğŸ“„ ë‚´ìš©:\")\n",
        "    for line in post['generated_content'].split('\\n')[:15]:\n",
        "        print(f\"    {line}\")\n",
        "    if len(post['generated_content'].split('\\n')) > 15:\n",
        "        print(f\"    ... (ì´í•˜ ìƒëµ)\")\n",
        "    print(f\"{'â”€' * 70}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-5IohjBwd5e"
      },
      "source": [
        "---\n",
        "## 6. ì™„ë£Œ\n",
        "\n",
        "### ìƒì„±ëœ íŒŒì¼\n",
        "| íŒŒì¼ | ì„¤ëª… |\n",
        "|------|------|\n",
        "| `generated_posts_gemini.csv` | ìƒì„±ëœ ì¸ê¸°ê¸€ (í‘œ í˜•íƒœ) |\n",
        "| `generated_posts_gemini.json` | ìƒì„±ëœ ì¸ê¸°ê¸€ (ìƒì„¸ JSON) |\n",
        "\n",
        "### í™œìš© ë°©ë²•\n",
        "- ìƒì„±ëœ ê¸€ì˜ í’ˆì§ˆì„ ìˆ˜ì‘ì—…ìœ¼ë¡œ ê²€í† \n",
        "- `factor_name`ê³¼ í‚¤ì›Œë“œ ì¡°í•©ì„ ë°”ê¿”ê°€ë©° ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ ìƒì„± ê°€ëŠ¥\n",
        "- `temperature`ë¥¼ 0.5~1.0 ì‚¬ì´ì—ì„œ ì¡°ì ˆí•˜ì—¬ ì°½ì˜ì„± ì¡°ì •"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}