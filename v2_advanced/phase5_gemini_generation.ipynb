{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fV61v7Kwd5Q"
      },
      "source": [
        "# Phase 5: Gemini API ê¸°ë°˜ ì¸ê¸°ê¸€ ìƒì„± ë° ê³ ë„í™”\n",
        "\n",
        "## ğŸ“Œ ëª©ì \n",
        "Phase 2ì—ì„œ ì¶”ì¶œí•œ **íŒ©í„°(ì¸ê¸°ìœ í˜•)**, **í”¼ì²˜(ì¸ê¸°ìš”ì†Œ)**, **í‚¤ì›Œë“œ** ì •ë³´ë¥¼\n",
        "Gemini API í”„ë¡¬í”„íŠ¸ì— í†µí•©í•˜ì—¬ ì„œë‹´ ìŠ¤íƒ€ì¼ ì¸ê¸°ê¸€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "ë˜í•œ, ê¸°ì¡´ Phase 4ì—ì„œ ìƒì„±ëœ ê²°ê³¼ë¬¼ì„ Geminië¥¼ í†µí•´ ë” ìì—°ìŠ¤ëŸ½ê²Œ êµì •(Refining)í•©ë‹ˆë‹¤.\n",
        "\n",
        "### í•µì‹¬ êµ¬ì¡°\n",
        "1. **ì‹ ê·œ ìƒì„±**: íŒ©í„° + í”¼ì²˜ + í‚¤ì›Œë“œ â†’ Gemini í”„ë¡¬í”„íŠ¸ â†’ Thinking(ì „ëµ) â†’ Title + Content\n",
        "2. **ê²°ê³¼ ì¬ì²˜ë¦¬ (Refining)**: Phase 4 Llama ìƒì„±ë¬¼ â†’ Gemini êµì • â†’ ê³ í’ˆì§ˆ ì¸ê¸°ê¸€\n",
        "\n",
        "### ì‚¬ì „ ì¡°ê±´\n",
        "- `phase2_dataset_v2.ipynb` ì‹¤í–‰ ì™„ë£Œ (`outputs/rpm_factors.json` ë“± ì¡´ì¬)\n",
        "- (ì„ íƒ) `phase4_generation_v2.ipynb` ì‹¤í–‰ ì™„ë£Œ (`outputs/generated_posts_v2.csv` ì¡´ì¬)\n",
        "- Colab Secretsì— `GEMINI_API_KEY` ë“±ë¡\n",
        "- GPU **ë¶ˆí•„ìš”** (API ê¸°ë°˜)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxCggjZjwd5V"
      },
      "source": [
        "---\n",
        "## 0. í™˜ê²½ ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiSRk2LBwd5W"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive, userdata\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import google.generativeai as genai\n",
        "import json, time, re, random\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# â”€â”€ Gemini API ì—°ê²° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "try:\n",
        "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    gemini_model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "    print(\"âœ… Gemini API ì—°ê²° ì™„ë£Œ\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ API ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
        "    print(\"ğŸ’¡ Colab ì™¼ìª½ ì—´ì‡  ì•„ì´ì½˜(Secrets)ì—ì„œ GEMINI_API_KEYë¥¼ ë“±ë¡í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGW87ahowd5Y"
      },
      "source": [
        "---\n",
        "## 1. RPM ë°ì´í„° ë¡œë“œ (íŒ©í„° + í”¼ì²˜ + í‚¤ì›Œë“œ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX8ytXa2wd5Y"
      },
      "outputs": [],
      "source": [
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/board_crawling\")\n",
        "OUTPUT_DIR   = PROJECT_ROOT / \"outputs\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# â”€â”€ íŒ©í„° ì •ë³´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "FACTORS_PATH = OUTPUT_DIR / \"rpm_factors.json\"\n",
        "if FACTORS_PATH.exists():\n",
        "    with open(FACTORS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        factors_data = json.load(f)\n",
        "    factor_names = [f[\"factor_name\"] for f in factors_data[\"factors\"]]\n",
        "    factor_descriptions = {\n",
        "        f[\"factor_name\"]: f.get(\"description\", \"\")\n",
        "        for f in factors_data[\"factors\"]\n",
        "    }\n",
        "    factor_stats = factors_data.get(\"factor_stats\", {})\n",
        "    print(f\"âœ… íŒ©í„° ë¡œë“œ: {len(factor_names)}ê°œ\")\n",
        "else:\n",
        "    factor_names = [\"ê°ì •ì _ê³µê°\", \"ìœ ë¨¸_ë°˜ì „\", \"ì •ë³´_ì „ë‹¬\", \"ì°¸ì—¬_ìœ ë„\", \"ì¼ìƒ_ê³µìœ \", \"ë…¼ë€_ì´ìŠˆ\"]\n",
        "    factor_descriptions = {n: \"\" for n in factor_names}\n",
        "    factor_stats = {}\n",
        "    print(\"âš ï¸ íŒ©í„° íŒŒì¼ ì—†ìŒ â†’ ê¸°ë³¸ íŒ©í„° ì‚¬ìš©\")\n",
        "\n",
        "# â”€â”€ í”¼ì²˜ ì •ë³´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "FEATURES_PATH = OUTPUT_DIR / \"rpm_features.json\"\n",
        "if FEATURES_PATH.exists():\n",
        "    with open(FEATURES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        all_features = json.load(f)\n",
        "    good_features = []\n",
        "    for pk, data in all_features.items():\n",
        "        for feat in data.get(\"features\", []):\n",
        "            fn = feat.get(\"feature_name\", feat.get(\"name\", \"\"))\n",
        "            ctx = feat.get(\"context\", \"\")\n",
        "            if fn and fn != \"ë‚´ìš©_êµ¬ì„±\" and len(ctx) > 10:\n",
        "                good_features.append({\"name\": fn, \"context\": ctx[:80]})\n",
        "    print(f\"âœ… í”¼ì²˜ ë¡œë“œ: ì˜ë¯¸ ìˆëŠ” í”¼ì²˜ {len(good_features)}ê°œ\")\n",
        "else:\n",
        "    good_features = []\n",
        "    print(\"âš ï¸ í”¼ì²˜ íŒŒì¼ ì—†ìŒ\")\n",
        "\n",
        "# â”€â”€ í† í”½ í‚¤ì›Œë“œ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "PROMPT_FILES = {\n",
        "    \"ìµê²Œ2\":     OUTPUT_DIR / \"ìµê²Œ2_topics_for_prompt.json\",\n",
        "    \"ììœ ê²Œì‹œíŒ\": OUTPUT_DIR / \"ììœ ê²Œì‹œíŒ_topics_for_prompt.json\",\n",
        "    \"ì—°ì• ìƒë‹´ì†Œ\": OUTPUT_DIR / \"ì—°ì• ìƒë‹´ì†Œ_topics_for_prompt.json\",\n",
        "    \"ìµê²Œ1\":     OUTPUT_DIR / \"ìµê²Œ1_topics_for_prompt.json\",\n",
        "}\n",
        "\n",
        "trend_keywords = {}\n",
        "for board, path in PROMPT_FILES.items():\n",
        "    if path.exists():\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            topics_data = json.load(f)\n",
        "        top_topics = sorted(topics_data, key=lambda x: len(x.get(\"representatives\", [])), reverse=True)[:5]\n",
        "        keywords = []\n",
        "        for topic in top_topics:\n",
        "            kw = topic.get(\"keywords\", [])\n",
        "            if isinstance(kw, list): keywords.extend(kw[:8])\n",
        "        trend_keywords[board] = list(dict.fromkeys(keywords))[:8]\n",
        "        print(f\"âœ… {board}: {trend_keywords[board]}\")\n",
        "\n",
        "if not trend_keywords:\n",
        "    trend_keywords = {\"ìµê²Œ2\": [\"ì‹œí—˜\", \"êµìˆ˜\", \"í•™ì \"], \"ììœ ê²Œì‹œíŒ\": [\"ì·¨ì—…\", \"ëŒ€í•™ì›\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH9n636xwd5Z"
      },
      "source": [
        "---\n",
        "## 2. Gemini í—¬í¼ + ìƒì„± í•¨ìˆ˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmzd-3oWwd5a"
      },
      "outputs": [],
      "source": [
        "def call_gemini(prompt: str, temperature: float = 0.7) -> str:\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            response = gemini_model.generate_content(\n",
        "                prompt,\n",
        "                generation_config=genai.types.GenerationConfig(\n",
        "                    temperature=temperature, max_output_tokens=2048,\n",
        "                ),\n",
        "            )\n",
        "            return response.text.strip()\n",
        "        except Exception as e:\n",
        "            if \"429\" in str(e): time.sleep(15 * (attempt + 1))\n",
        "            else: return \"\"\n",
        "    return \"\"\n",
        "\n",
        "def generate_post_gemini(board_name, keywords, factor_name, factor_desc=\"\"):\n",
        "    sampled_features = random.sample(good_features, min(5, len(good_features))) if good_features else []\n",
        "    feature_sample = \"\\n\".join([f\"- {f['name']}: {f['context']}\" for f in sampled_features])\n",
        "\n",
        "    prompt = f\"\"\"ë‹¹ì‹ ì€ ì„œê°•ëŒ€ ì»¤ë®¤ë‹ˆí‹° 'ì„œë‹´'ì˜ ì¸ê¸°ê¸€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
        "ì•„ë˜ ì¡°ê±´ìœ¼ë¡œ ì¸ê¸°ê¸€ì„ ì‘ì„±í•˜ì„¸ìš”.\n",
        "\n",
        "[ê²Œì‹œíŒ] {board_name}\n",
        "[í‚¤ì›Œë“œ] {', '.join(keywords)}\n",
        "[íŒ©í„°] {factor_name}: {factor_desc}\n",
        "[í”¼ì²˜ ì˜ˆì‹œ]\\n{feature_sample}\n",
        "\n",
        "í˜•ì‹:\n",
        "<Thinking>ì „ëµ 2~3ë¬¸ì¥</Thinking>\n",
        "<Title>í´ë¦­ìœ ë°œ ì œëª© (ì„œë‹´ ë§íˆ¬)</Title>\n",
        "<Content>ì‹¤ì œ ë³¸ë¬¸ (ë°˜ë§, ìì—°ìŠ¤ëŸ½ê²Œ)</Content>\"\"\"\n",
        "\n",
        "    result = call_gemini(prompt, 0.8)\n",
        "    res_dict = {\"board_name\": board_name, \"keywords\": \", \".join(keywords), \"factor\": factor_name}\n",
        "    for tag in [\"Thinking\", \"Title\", \"Content\"]:\n",
        "        match = re.search(f'<{tag}>(.*?)</{tag}>', result, re.DOTALL)\n",
        "        res_dict[f\"generated_{tag.lower()}\" if tag != \"Thinking\" else \"thinking\"] = match.group(1).strip() if match else \"\"\n",
        "    res_dict[\"timestamp\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    return res_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgfC3joEwd5b"
      },
      "source": [
        "---\n",
        "## 3. ì‹ ê·œ ìƒì„± ì‹¤í–‰ (ì¤‘ê°„ ì €ì¥ í¬í•¨)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULICPcpjwd5b"
      },
      "outputs": [],
      "source": [
        "generated_posts = []\n",
        "CACHE_FILE = OUTPUT_DIR / \"generated_posts_gemini_temp.json\"\n",
        "SAVE_INTERVAL = 5\n",
        "\n",
        "boards = list(trend_keywords.keys())\n",
        "factors = factor_names[:3]\n",
        "\n",
        "for b_idx, board in enumerate(boards):\n",
        "    for f_idx, factor in enumerate(factors):\n",
        "        print(f\"ğŸ”§ [{board}] {factor} ìƒì„± ì¤‘...\")\n",
        "        res = generate_post_gemini(board, trend_keywords[board], factor, factor_descriptions.get(factor, \"\"))\n",
        "        generated_posts.append(res)\n",
        "        \n",
        "        if len(generated_posts) % SAVE_INTERVAL == 0:\n",
        "            with open(CACHE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(generated_posts, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"  ğŸ’¾ ì¤‘ê°„ ì €ì¥ë¨ ({len(generated_posts)}ê±´)\")\n",
        "        time.sleep(1)\n",
        "\n",
        "final_csv = OUTPUT_DIR / \"generated_posts_gemini.csv\"\n",
        "pd.DataFrame(generated_posts).to_csv(final_csv, index=False, encoding=\"utf-8-sig\")\n",
        "print(f\"âœ… ìƒì„± ì™„ë£Œ! {final_csv}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Phase 4 ê²°ê³¼ ì¬ì²˜ë¦¬ (Refining)\n",
        "\n",
        "Phase 4ì—ì„œ Llama ëª¨ë¸ì´ ìƒì„±í•œ ì´ˆì•ˆì„ ë¡œë“œí•˜ì—¬ Geminiê°€ ë” ìì—°ìŠ¤ëŸ½ê²Œ êµì •í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PHASE4_CSV = OUTPUT_DIR / \"generated_posts_v2.csv\"\n",
        "REFINED_CSV = OUTPUT_DIR / \"generated_posts_refined.csv\"\n",
        "\n",
        "if PHASE4_CSV.exists():\n",
        "    df_p4 = pd.read_csv(PHASE4_CSV)\n",
        "    refined_data = []\n",
        "    \n",
        "    print(f\"ğŸ“ Phase 4 ë°ì´í„° {len(df_p4)}ê±´ ì¬ì²˜ë¦¬ ì‹œì‘...\")\n",
        "    \n",
        "    for idx, row in tqdm(df_p4.iterrows(), total=len(df_p4)):\n",
        "        prompt = f\"\"\"ì•„ë˜ëŠ” ì¸ê³µì§€ëŠ¥ì´ ì‘ì„±í•œ ì»¤ë®¤ë‹ˆí‹° 'ì„œë‹´'ì˜ ì¸ê¸°ê¸€ ì´ˆì•ˆì´ì•¼.\n",
        "ì´ ê¸€ì„ ì‹¤ì œ ì„œê°•ëŒ€ í•™ìƒì´ ì“´ ê²ƒì²˜ëŸ¼ í›¨ì”¬ ë” ìì—°ìŠ¤ëŸ½ê³  ìƒìƒí•˜ê²Œ ê³ ì³ì¤˜.\n",
        "\n",
        "[ì´ˆì•ˆ ì œëª©]: {row.get('generated_title', '')}\n",
        "[ì´ˆì•ˆ ë³¸ë¬¸]:\\n{row.get('generated_content', '')}\n",
        "\n",
        "ê·œì¹™:\n",
        "- ë§íˆ¬ëŠ” ì¹œê·¼í•œ ë°˜ë§ë¡œ ìˆ˜ì • (ì„œë‹´ íŠ¹ìœ ì˜ ë¶„ìœ„ê¸° ë°˜ì˜)\n",
        "- ë„ˆë¬´ ì •ì¤‘í•˜ê±°ë‚˜ ì„¤ëª…ì¡°ì¸ ë¶€ë¶„ì€ ê³¼ê°íˆ ì‚­ì œ\n",
        "- <Title>, <Content> íƒœê·¸ë¡œ ê°ì‹¸ì„œ ì‘ë‹µí•´ì¤˜.\"\"\"\n",
        "        \n",
        "        res_text = call_gemini(prompt, 0.7)\n",
        "        \n",
        "        new_title = re.search(r'<Title>(.*?)</Title>', res_text, re.DOTALL)\n",
        "        new_content = re.search(r'<Content>(.*?)</Content>', res_text, re.DOTALL)\n",
        "        \n",
        "        refined_data.append({\n",
        "            \"board_name\": row.get('board_name'),\n",
        "            \"factor\": row.get('factor'),\n",
        "            \"original_title\": row.get('generated_title'),\n",
        "            \"refined_title\": new_title.group(1).strip() if new_title else row.get('generated_title'),\n",
        "            \"refined_content\": new_content.group(1).strip() if new_content else res_text,\n",
        "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        })\n",
        "        time.sleep(1)\n",
        "    \n",
        "    pd.DataFrame(refined_data).to_csv(REFINED_CSV, index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"âœ… ì¬ì²˜ë¦¬ ì™„ë£Œ! {REFINED_CSV}\")\n",
        "    display(pd.DataFrame(refined_data).head())\n",
        "else:\n",
        "    print(\"âš ï¸ Phase 4 ê²°ê³¼ íŒŒì¼ì´ ì—†ì–´ ì¬ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. ê²°ê³¼ ìƒì„¸ ê²€í† "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== ì‹ ê·œ ìƒì„± ìƒ˜í”Œ ===\")\n",
        "for p in generated_posts[:2]:\n",
        "    print(f\"[ì œëª©] {p['generated_title']}\\n[Thinking] {p['thinking']}\\n{'-'*20}\")\n",
        "\n",
        "if 'refined_data' in locals() and refined_data:\n",
        "    print(\"\\n=== ì¬ì²˜ë¦¬(Refined) ìƒ˜í”Œ ===\")\n",
        "    for r in refined_data[:2]:\n",
        "        print(f\"[Original] {r['original_title']}\\n[Refined] {r['refined_title']}\\n{'-'*20}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}